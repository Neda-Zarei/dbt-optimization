{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.11.0b3", "generated_at": "2026-01-29T16:54:41.926003Z", "invocation_id": "662b4662-28f9-4fb5-9a5e-5ea9d7b8e3c3", "invocation_started_at": "2026-01-29T16:53:38.018323Z", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.094713Z", "completed_at": "2026-01-29T16:53:48.117619Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.129662Z", "completed_at": "2026-01-29T16:53:48.435324Z"}], "thread_id": "Thread-2", "execution_time": 0.35193371772766113, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710aa"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_benchmarks", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: stg_benchmarks\n-- Description: Benchmark index data for performance comparison\n\nwith source as (\n    select\n        benchmark_id,\n        benchmark_name,\n        benchmark_ticker,\n        asset_class,\n        region,\n        is_active,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.benchmarks\n),\n\n-- ISSUE: Subquery for deduplication\ndeduplicated as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (partition by benchmark_id order by updated_at desc) as rn\n        from source\n    )\n    where rn = 1\n)\n\nselect\n    benchmark_id,\n    trim(benchmark_name) as benchmark_name,\n    upper(trim(benchmark_ticker)) as benchmark_ticker,\n    upper(asset_class) as asset_class,\n    upper(region) as region,\n    is_active,\n    created_at,\n    updated_at\nfrom deduplicated\nwhere is_active = true", "relation_name": "DBT_DEMO.DEV_pipeline_c.stg_benchmarks", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.098406Z", "completed_at": "2026-01-29T16:53:48.118063Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.140870Z", "completed_at": "2026-01-29T16:53:48.439963Z"}], "thread_id": "Thread-3", "execution_time": 0.35620927810668945, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e3200072082"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_brokers", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: stg_brokers\n-- Description: Staging model for broker information\n\nwith source as (\n    select\n        broker_id,\n        broker_name,\n        broker_type,\n        region,\n        is_active,\n        commission_rate,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.brokers\n),\n\ndeduplicated as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (partition by broker_id order by updated_at desc) as rn\n        from source\n    )\n    where rn = 1\n)\n\nselect\n    broker_id,\n    trim(broker_name) as broker_name,\n    upper(broker_type) as broker_type,\n    upper(region) as region,\n    is_active,\n    commission_rate,\n    created_at,\n    updated_at\nfrom deduplicated\nwhere is_active = true", "relation_name": "DBT_DEMO.DEV_pipeline_b.stg_brokers", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.085627Z", "completed_at": "2026-01-29T16:53:48.105008Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.105357Z", "completed_at": "2026-01-29T16:53:48.441413Z"}], "thread_id": "Thread-1", "execution_time": 0.3583807945251465, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e320007207e"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_benchmark_returns", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: stg_benchmark_returns\n-- Description: Daily benchmark return data\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Self-join for cumulative returns (inefficient)\n-- 2. Multiple window functions\n\nwith source as (\n    select\n        benchmark_id,\n        return_date,\n        daily_return,\n        index_level,\n        created_at\n    from DBT_DEMO.DEV.benchmark_returns\n    where return_date >= '2020-01-01'\n),\n\n-- ISSUE: Multiple window functions that could be consolidated\nwith_cumulative as (\n    select\n        benchmark_id,\n        return_date,\n        daily_return,\n        index_level,\n        -- ISSUE: Separate window functions for each period\n        exp(sum(ln(1 + daily_return)) over (\n            partition by benchmark_id\n            order by return_date\n            rows between unbounded preceding and current row\n        )) - 1 as cumulative_return,\n        exp(sum(ln(1 + daily_return)) over (\n            partition by benchmark_id\n            order by return_date\n            rows between 29 preceding and current row\n        )) - 1 as return_30d,\n        exp(sum(ln(1 + daily_return)) over (\n            partition by benchmark_id\n            order by return_date\n            rows between 89 preceding and current row\n        )) - 1 as return_90d,\n        exp(sum(ln(1 + daily_return)) over (\n            partition by benchmark_id\n            order by return_date\n            rows between 364 preceding and current row\n        )) - 1 as return_1y,\n        stddev(daily_return) over (\n            partition by benchmark_id\n            order by return_date\n            rows between 251 preceding and current row\n        ) * sqrt(252) as annualized_volatility,\n        created_at\n    from source\n)\n\nselect * from with_cumulative", "relation_name": "DBT_DEMO.DEV_pipeline_c.stg_benchmark_returns", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.101122Z", "completed_at": "2026-01-29T16:53:48.129333Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.143631Z", "completed_at": "2026-01-29T16:53:48.498421Z"}], "thread_id": "Thread-4", "execution_time": 0.414355993270874, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e3200073156"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_cashflows", "compiled": true, "compiled_code": "-- Pipeline A: Simple Cashflow Pipeline\n-- Model: stg_cashflows\n-- Description: Staging model for raw cashflow data\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Unnecessary DISTINCT (source already unique)\n-- 2. Late filtering (should push date filter upstream)\n-- 3. Non-optimal date casting\n\nwith source as (\n    select distinct  -- ISSUE: Unnecessary DISTINCT, source has unique constraint\n        cashflow_id,\n        portfolio_id,\n        cashflow_type,\n        cashflow_date,\n        amount,\n        currency,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.cashflows\n),\n\n-- ISSUE: Heavy transformation before filtering\nconverted as (\n    select\n        cashflow_id,\n        portfolio_id,\n        upper(cashflow_type) as cashflow_type,\n        cast(cashflow_date as date) as cashflow_date,\n        cast(amount as decimal(18,2)) as amount,\n        upper(currency) as currency,\n        cast(created_at as timestamp) as created_at,\n        cast(updated_at as timestamp) as updated_at\n    from source\n),\n\n-- ISSUE: Filter applied after transformation, should be earlier\nfiltered as (\n    select *\n    from converted\n    where cashflow_date >= '2020-01-01'\n      and cashflow_date <= '2024-12-31'\n)\n\nselect * from filtered", "relation_name": "DBT_DEMO.DEV_pipeline_a.stg_cashflows", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.459872Z", "completed_at": "2026-01-29T16:53:48.469703Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.470064Z", "completed_at": "2026-01-29T16:53:48.707006Z"}], "thread_id": "Thread-1", "execution_time": 0.25748300552368164, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710ae"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_portfolio_benchmarks", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: stg_portfolio_benchmarks\n-- Description: Mapping of portfolios to their benchmarks\n\nwith source as (\n    select\n        portfolio_id,\n        benchmark_id,\n        is_primary,\n        start_date,\n        end_date,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.portfolio_benchmarks\n)\n\nselect\n    portfolio_id,\n    benchmark_id,\n    is_primary,\n    cast(start_date as date) as start_date,\n    cast(end_date as date) as end_date,\n    created_at,\n    updated_at\nfrom source\nwhere end_date is null or end_date >= current_date()", "relation_name": "DBT_DEMO.DEV_pipeline_c.stg_portfolio_benchmarks", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.455492Z", "completed_at": "2026-01-29T16:53:48.466405Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.466791Z", "completed_at": "2026-01-29T16:53:48.740011Z"}], "thread_id": "Thread-3", "execution_time": 0.2907900810241699, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710b2"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_market_prices", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: stg_market_prices\n-- Description: Staging model for daily market prices\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Self-join for prior day prices (inefficient)\n-- 2. Late aggregation\n-- 3. Multiple window functions that could be consolidated\n\nwith source as (\n    select\n        security_id,\n        price_date,\n        open_price,\n        high_price,\n        low_price,\n        close_price,\n        volume,\n        created_at\n    from DBT_DEMO.DEV.market_prices\n    where price_date >= '2020-01-01'\n),\n\n-- ISSUE: Self-join to get prior day price (should use LAG)\nwith_prior_day as (\n    select\n        curr.security_id,\n        curr.price_date,\n        curr.open_price,\n        curr.high_price,\n        curr.low_price,\n        curr.close_price,\n        curr.volume,\n        prev.close_price as prior_close,\n        prev.volume as prior_volume\n    from source curr\n    left join source prev\n        on curr.security_id = prev.security_id\n        and curr.price_date = dateadd('day', 1, prev.price_date)  -- ISSUE: Doesn't handle weekends\n),\n\n-- ISSUE: Multiple separate window functions\nwith_returns as (\n    select\n        *,\n        -- Daily return\n        case\n            when prior_close > 0\n            then (close_price - prior_close) / prior_close\n            else null\n        end as daily_return,\n        -- ISSUE: These could be computed together\n        avg(close_price) over (\n            partition by security_id\n            order by price_date\n            rows between 19 preceding and current row\n        ) as ma_20,\n        avg(close_price) over (\n            partition by security_id\n            order by price_date\n            rows between 49 preceding and current row\n        ) as ma_50,\n        avg(close_price) over (\n            partition by security_id\n            order by price_date\n            rows between 199 preceding and current row\n        ) as ma_200,\n        stddev(close_price) over (\n            partition by security_id\n            order by price_date\n            rows between 19 preceding and current row\n        ) as volatility_20d,\n        avg(volume) over (\n            partition by security_id\n            order by price_date\n            rows between 19 preceding and current row\n        ) as avg_volume_20d\n    from with_prior_day\n),\n\n-- ISSUE: Another pass for more calculations\nfinal as (\n    select\n        *,\n        case\n            when ma_20 > ma_50 and ma_50 > ma_200 then 'BULLISH'\n            when ma_20 < ma_50 and ma_50 < ma_200 then 'BEARISH'\n            else 'NEUTRAL'\n        end as trend_signal,\n        case\n            when volume > avg_volume_20d * 2 then 'HIGH'\n            when volume < avg_volume_20d * 0.5 then 'LOW'\n            else 'NORMAL'\n        end as volume_signal\n    from with_returns\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_b.stg_market_prices", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.450912Z", "completed_at": "2026-01-29T16:53:48.462904Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.463235Z", "completed_at": "2026-01-29T16:53:48.798658Z"}], "thread_id": "Thread-2", "execution_time": 0.3498108386993408, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e320007315a"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_fund_hierarchy", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: stg_fund_hierarchy\n-- Description: Fund and portfolio hierarchy for roll-up reporting\n\nwith source as (\n    select\n        entity_id,\n        entity_name,\n        entity_type,\n        parent_entity_id,\n        hierarchy_level,\n        is_active,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.fund_hierarchy\n)\n\nselect\n    entity_id,\n    trim(entity_name) as entity_name,\n    upper(entity_type) as entity_type,\n    parent_entity_id,\n    hierarchy_level,\n    is_active,\n    created_at,\n    updated_at\nfrom source\nwhere is_active = true", "relation_name": "DBT_DEMO.DEV_pipeline_c.stg_fund_hierarchy", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.501320Z", "completed_at": "2026-01-29T16:53:48.560015Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.560394Z", "completed_at": "2026-01-29T16:53:48.814626Z"}], "thread_id": "Thread-4", "execution_time": 0.31403517723083496, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e3200072086"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_portfolios", "compiled": true, "compiled_code": "-- Pipeline A: Simple Cashflow Pipeline\n-- Model: stg_portfolios\n-- Description: Staging model for portfolio master data\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Subquery for deduplication instead of QUALIFY\n-- 2. Multiple passes over data\n\nwith source as (\n    select\n        portfolio_id,\n        portfolio_name,\n        portfolio_type,\n        fund_id,\n        inception_date,\n        status,\n        currency,\n        created_at,\n        updated_at,\n        row_number() over (\n            partition by portfolio_id\n            order by updated_at desc\n        ) as rn\n    from DBT_DEMO.DEV.portfolios\n),\n\n-- ISSUE: Using subquery filter instead of QUALIFY\ndeduplicated as (\n    select\n        portfolio_id,\n        portfolio_name,\n        portfolio_type,\n        fund_id,\n        inception_date,\n        status,\n        currency,\n        created_at,\n        updated_at\n    from source\n    where rn = 1  -- ISSUE: Should use QUALIFY in Snowflake\n),\n\n-- ISSUE: Another pass just for active filter\nactive_only as (\n    select *\n    from deduplicated\n    where status = 'ACTIVE'\n)\n\nselect * from active_only", "relation_name": "DBT_DEMO.DEV_pipeline_a.stg_portfolios", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.710522Z", "completed_at": "2026-01-29T16:53:48.714797Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.715247Z", "completed_at": "2026-01-29T16:53:49.057987Z"}], "thread_id": "Thread-1", "execution_time": 0.3484029769897461, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e320007315e"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_positions_daily", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: stg_positions_daily\n-- Description: Daily position snapshots from source system\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Heavy transformations before filtering\n-- 2. Unnecessary type conversions\n-- 3. Could push filters upstream\n\nwith source as (\n    select\n        position_id,\n        portfolio_id,\n        security_id,\n        position_date,\n        quantity,\n        cost_basis_price,\n        cost_basis_value,\n        market_price,\n        market_value,\n        market_value_usd,\n        unrealized_pnl,\n        unrealized_pnl_pct,\n        weight_pct,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.positions_daily\n),\n\n-- ISSUE: Transformations applied to all rows before filter\ntransformed as (\n    select\n        position_id,\n        portfolio_id,\n        security_id,\n        cast(position_date as date) as position_date,\n        cast(quantity as decimal(18,6)) as quantity,\n        cast(cost_basis_price as decimal(18,4)) as cost_basis_price,\n        cast(cost_basis_value as decimal(18,2)) as cost_basis_value,\n        cast(market_price as decimal(18,4)) as market_price,\n        cast(market_value as decimal(18,2)) as market_value,\n        cast(market_value_usd as decimal(18,2)) as market_value_usd,\n        cast(unrealized_pnl as decimal(18,2)) as unrealized_pnl,\n        cast(unrealized_pnl_pct as decimal(10,4)) as unrealized_pnl_pct,\n        cast(weight_pct as decimal(10,6)) as weight_pct,\n        created_at,\n        updated_at\n    from source\n),\n\n-- ISSUE: Filter applied last\nfiltered as (\n    select *\n    from transformed\n    where position_date >= '2020-01-01'\n)\n\nselect * from filtered", "relation_name": "DBT_DEMO.DEV_pipeline_c.stg_positions_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.743082Z", "completed_at": "2026-01-29T16:53:48.746602Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.746911Z", "completed_at": "2026-01-29T16:53:49.076423Z"}], "thread_id": "Thread-3", "execution_time": 0.33413100242614746, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e3200073162"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_securities", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: stg_securities\n-- Description: Staging model for security master data\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Nested subqueries instead of QUALIFY\n-- 2. Multiple deduplication passes\n\nwith source as (\n    select\n        security_id,\n        ticker,\n        security_name,\n        security_type,\n        asset_class,\n        sector,\n        industry,\n        currency,\n        exchange,\n        is_active,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.securities\n),\n\n-- ISSUE: Complex deduplication using subquery\ndeduplicated as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (\n                partition by security_id\n                order by updated_at desc\n            ) as rn\n        from source\n    ) sub\n    where rn = 1  -- ISSUE: Should use QUALIFY\n),\n\n-- ISSUE: Separate CTE for type standardization\nstandardized as (\n    select\n        security_id,\n        upper(trim(ticker)) as ticker,\n        trim(security_name) as security_name,\n        -- ISSUE: Repeated CASE logic found in other models\n        case\n            when security_type in ('STOCK', 'EQUITY', 'COMMON') then 'EQUITY'\n            when security_type in ('BOND', 'NOTE', 'DEBENTURE') then 'FIXED_INCOME'\n            when security_type in ('OPTION', 'FUTURE', 'SWAP') then 'DERIVATIVE'\n            when security_type in ('ETF', 'MUTUAL_FUND') then 'FUND'\n            else 'OTHER'\n        end as security_type_standardized,\n        security_type as security_type_original,\n        upper(asset_class) as asset_class,\n        sector,\n        industry,\n        upper(currency) as currency,\n        exchange,\n        is_active,\n        created_at,\n        updated_at\n    from deduplicated\n)\n\nselect * from standardized\nwhere is_active = true", "relation_name": "DBT_DEMO.DEV_pipeline_b.stg_securities", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.818854Z", "completed_at": "2026-01-29T16:53:48.822602Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.822930Z", "completed_at": "2026-01-29T16:53:49.106383Z"}], "thread_id": "Thread-4", "execution_time": 0.2884023189544678, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710b6"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_valuations", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: stg_valuations\n-- Description: Portfolio valuation data (NAV, etc.)\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Deduplication via subquery\n-- 2. Heavy calculations before filtering\n\nwith source as (\n    select\n        valuation_id,\n        portfolio_id,\n        valuation_date,\n        nav,\n        nav_per_share,\n        shares_outstanding,\n        gross_assets,\n        total_liabilities,\n        net_assets,\n        currency,\n        fx_rate_to_usd,\n        nav_usd,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.valuations\n),\n\n-- ISSUE: Deduplication using subquery\ndeduplicated as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (\n                partition by portfolio_id, valuation_date\n                order by updated_at desc\n            ) as rn\n        from source\n    )\n    where rn = 1\n),\n\n-- ISSUE: Filter applied after deduplication\nfiltered as (\n    select\n        valuation_id,\n        portfolio_id,\n        cast(valuation_date as date) as valuation_date,\n        cast(nav as decimal(18,2)) as nav,\n        cast(nav_per_share as decimal(18,6)) as nav_per_share,\n        cast(shares_outstanding as decimal(18,6)) as shares_outstanding,\n        cast(gross_assets as decimal(18,2)) as gross_assets,\n        cast(total_liabilities as decimal(18,2)) as total_liabilities,\n        cast(net_assets as decimal(18,2)) as net_assets,\n        upper(currency) as currency,\n        cast(fx_rate_to_usd as decimal(18,8)) as fx_rate_to_usd,\n        cast(nav_usd as decimal(18,2)) as nav_usd,\n        created_at,\n        updated_at\n    from deduplicated\n    where valuation_date >= '2020-01-01'\n)\n\nselect * from filtered", "relation_name": "DBT_DEMO.DEV_pipeline_c.stg_valuations", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:48.801887Z", "completed_at": "2026-01-29T16:53:48.805783Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:48.806119Z", "completed_at": "2026-01-29T16:53:49.130695Z"}], "thread_id": "Thread-2", "execution_time": 0.3296051025390625, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e320007208a"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.stg_trades", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: stg_trades\n-- Description: Staging model for trade transactions\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Complex CASE statements that repeat\n-- 2. Multiple CTEs doing similar transformations\n-- 3. Unnecessary string operations\n\nwith source as (\n    select\n        trade_id,\n        portfolio_id,\n        security_id,\n        broker_id,\n        trade_date,\n        settlement_date,\n        trade_type,\n        quantity,\n        price,\n        gross_amount,\n        commission,\n        fees,\n        net_amount,\n        currency,\n        created_at,\n        updated_at\n    from DBT_DEMO.DEV.trades\n),\n\n-- ISSUE: Repeated CASE statements for trade categorization\ncategorized as (\n    select\n        *,\n        -- ISSUE: This logic is repeated in multiple models\n        case\n            when trade_type in ('BUY', 'COVER') then 'PURCHASE'\n            when trade_type in ('SELL', 'SHORT') then 'SALE'\n            when trade_type in ('DIVIDEND', 'INTEREST') then 'INCOME'\n            else 'OTHER'\n        end as trade_category,\n        case\n            when abs(net_amount) >= 10000000 then 'LARGE'\n            when abs(net_amount) >= 1000000 then 'MEDIUM'\n            when abs(net_amount) >= 100000 then 'SMALL'\n            else 'MICRO'\n        end as trade_size_bucket,\n        -- ISSUE: Redundant string manipulation\n        upper(trim(trade_type)) as trade_type_clean,\n        upper(trim(currency)) as currency_clean\n    from source\n),\n\n-- ISSUE: Another pass just for date calculations\nwith_dates as (\n    select\n        *,\n        datediff('day', trade_date, settlement_date) as settlement_days,\n        date_trunc('month', trade_date) as trade_month,\n        date_trunc('quarter', trade_date) as trade_quarter,\n        extract(year from trade_date) as trade_year,\n        extract(month from trade_date) as trade_month_num,\n        dayofweek(trade_date) as trade_day_of_week\n    from categorized\n),\n\n-- ISSUE: Late filtering\nfiltered as (\n    select *\n    from with_dates\n    where trade_date >= '2020-01-01'\n)\n\nselect * from filtered", "relation_name": "DBT_DEMO.DEV_pipeline_b.stg_trades", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.146713Z", "completed_at": "2026-01-29T16:53:49.151598Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.152355Z", "completed_at": "2026-01-29T16:53:49.544780Z"}], "thread_id": "Thread-2", "execution_time": 0.3998398780822754, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710ba"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_portfolio_returns_daily", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_portfolio_returns_daily\n-- Description: Calculate daily portfolio returns from NAV\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Self-join for prior day NAV (should use LAG)\n-- 2. Multiple passes for return calculations\n-- 3. Complex window functions\n\nwith valuations as (\n    select * from DBT_DEMO.DEV_pipeline_c.stg_valuations\n),\n\ncashflows as (\n    select\n        portfolio_id,\n        cashflow_date,\n        sum(case when cashflow_type = 'CONTRIBUTION' then amount else 0 end) as contributions,\n        sum(case when cashflow_type = 'DISTRIBUTION' then amount else 0 end) as distributions\n    from DBT_DEMO.DEV_pipeline_a.stg_cashflows\n    group by 1, 2\n),\n\n-- ISSUE: Self-join instead of LAG for prior NAV\nwith_prior_nav as (\n    select\n        curr.portfolio_id,\n        curr.valuation_date,\n        curr.nav,\n        curr.nav_usd,\n        prev.nav as prior_nav,\n        prev.nav_usd as prior_nav_usd,\n        coalesce(cf.contributions, 0) as contributions,\n        coalesce(cf.distributions, 0) as distributions\n    from valuations curr\n    left join valuations prev\n        on curr.portfolio_id = prev.portfolio_id\n        and curr.valuation_date = dateadd('day', 1, prev.valuation_date)\n    left join cashflows cf\n        on curr.portfolio_id = cf.portfolio_id\n        and curr.valuation_date = cf.cashflow_date\n),\n\n-- ISSUE: Modified Dietz calculation done inefficiently\nwith_daily_return as (\n    select\n        portfolio_id,\n        valuation_date,\n        nav,\n        nav_usd,\n        prior_nav,\n        prior_nav_usd,\n        contributions,\n        distributions,\n        -- Simple return\n        case\n            when prior_nav > 0\n            then (nav - prior_nav - contributions + distributions) / prior_nav\n            else null\n        end as daily_return_simple,\n        -- Modified Dietz (approximation)\n        case\n            when (prior_nav + contributions * 0.5) > 0\n            then (nav - prior_nav - contributions + distributions) / (prior_nav + contributions * 0.5 - distributions * 0.5)\n            else null\n        end as daily_return_mod_dietz\n    from with_prior_nav\n),\n\n-- ISSUE: Multiple window functions for different periods\nwith_rolling_returns as (\n    select\n        *,\n        -- Cumulative return using log returns\n        exp(sum(ln(1 + coalesce(daily_return_mod_dietz, 0))) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between unbounded preceding and current row\n        )) - 1 as cumulative_return,\n        -- Rolling period returns\n        exp(sum(ln(1 + coalesce(daily_return_mod_dietz, 0))) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 6 preceding and current row\n        )) - 1 as return_1w,\n        exp(sum(ln(1 + coalesce(daily_return_mod_dietz, 0))) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 29 preceding and current row\n        )) - 1 as return_1m,\n        exp(sum(ln(1 + coalesce(daily_return_mod_dietz, 0))) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 89 preceding and current row\n        )) - 1 as return_3m,\n        exp(sum(ln(1 + coalesce(daily_return_mod_dietz, 0))) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 179 preceding and current row\n        )) - 1 as return_6m,\n        exp(sum(ln(1 + coalesce(daily_return_mod_dietz, 0))) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 364 preceding and current row\n        )) - 1 as return_1y,\n        -- Rolling volatility\n        stddev(daily_return_mod_dietz) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 29 preceding and current row\n        ) * sqrt(252) as volatility_1m,\n        stddev(daily_return_mod_dietz) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 251 preceding and current row\n        ) * sqrt(252) as volatility_1y\n    from with_daily_return\n)\n\nselect * from with_rolling_returns", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_portfolio_returns_daily", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.108656Z", "completed_at": "2026-01-29T16:53:49.131292Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.132416Z", "completed_at": "2026-01-29T16:53:49.599226Z"}], "thread_id": "Thread-3", "execution_time": 0.4924328327178955, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e3200072092"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_position_attribution", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_position_attribution\n-- Description: Attribution analysis at position level\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Heavy multi-way join\n-- 2. Complex attribution calculations\n-- 3. Multiple window functions\n\nwith positions as (\n    select * from DBT_DEMO.DEV_pipeline_c.stg_positions_daily\n),\n\nsecurities as (\n    select * from DBT_DEMO.DEV_pipeline_b.stg_securities\n),\n\nmarket_prices as (\n    select * from DBT_DEMO.DEV_pipeline_b.stg_market_prices\n),\n\n-- ISSUE: Heavy 3-way join\nenriched_positions as (\n    select\n        p.portfolio_id,\n        p.security_id,\n        p.position_date,\n        p.quantity,\n        p.market_value_usd,\n        p.weight_pct,\n        s.ticker,\n        s.security_type_standardized as security_type,\n        s.asset_class,\n        s.sector,\n        s.industry,\n        mp.daily_return as security_return,\n        mp.close_price,\n        mp.ma_20,\n        mp.ma_50,\n        mp.volatility_20d\n    from positions p\n    inner join securities s\n        on p.security_id = s.security_id\n    left join market_prices mp\n        on p.security_id = mp.security_id\n        and p.position_date = mp.price_date\n),\n\n-- ISSUE: Window functions for prior day weight\nwith_prior_weight as (\n    select\n        *,\n        lag(weight_pct, 1) over (\n            partition by portfolio_id, security_id\n            order by position_date\n        ) as prior_weight_pct,\n        lag(market_value_usd, 1) over (\n            partition by portfolio_id, security_id\n            order by position_date\n        ) as prior_market_value\n    from enriched_positions\n),\n\n-- ISSUE: Attribution calculations\nwith_attribution as (\n    select\n        *,\n        -- Contribution to return\n        coalesce(prior_weight_pct, weight_pct) * coalesce(security_return, 0) as contribution_to_return,\n        -- Allocation effect (simplified Brinson)\n        (weight_pct - coalesce(prior_weight_pct, weight_pct)) * coalesce(security_return, 0) as allocation_effect,\n        -- Position P&L\n        market_value_usd - coalesce(prior_market_value, market_value_usd) as position_pnl\n    from with_prior_weight\n)\n\nselect * from with_attribution", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_position_attribution", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.123955Z", "completed_at": "2026-01-29T16:53:49.135680Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.136625Z", "completed_at": "2026-01-29T16:53:49.661701Z"}], "thread_id": "Thread-4", "execution_time": 0.5391452312469482, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e3200073166"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_benchmark_aligned", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_benchmark_aligned\n-- Description: Align benchmark returns with portfolio dates for comparison\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Heavy join between portfolios and benchmarks\n-- 2. Could pre-filter benchmarks\n\nwith portfolio_dates as (\n    select distinct\n        portfolio_id,\n        valuation_date\n    from DBT_DEMO.DEV_pipeline_c.stg_valuations\n),\n\nportfolio_benchmarks as (\n    select * from DBT_DEMO.DEV_pipeline_c.stg_portfolio_benchmarks\n),\n\nbenchmark_returns as (\n    select * from DBT_DEMO.DEV_pipeline_c.stg_benchmark_returns\n),\n\n-- ISSUE: Cross-join like pattern (portfolio dates x benchmarks)\naligned as (\n    select\n        pd.portfolio_id,\n        pd.valuation_date,\n        pb.benchmark_id,\n        1.0 as benchmark_weight,  -- Default weight since not in source\n        pb.is_primary,\n        br.daily_return as benchmark_daily_return,\n        br.cumulative_return as benchmark_cumulative_return,\n        br.return_30d as benchmark_return_30d,\n        br.return_90d as benchmark_return_90d,\n        br.return_1y as benchmark_return_1y,\n        br.annualized_volatility as benchmark_volatility\n    from portfolio_dates pd\n    inner join portfolio_benchmarks pb\n        on pd.portfolio_id = pb.portfolio_id\n        and pd.valuation_date >= pb.start_date\n        and (pb.end_date is null or pd.valuation_date <= pb.end_date)\n    left join benchmark_returns br\n        on pb.benchmark_id = br.benchmark_id\n        and pd.valuation_date = br.return_date\n)\n\nselect * from aligned", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_benchmark_aligned", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.602499Z", "completed_at": "2026-01-29T16:53:49.606502Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.606869Z", "completed_at": "2026-01-29T16:53:50.010857Z"}], "thread_id": "Thread-3", "execution_time": 0.40946316719055176, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710be"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_risk_metrics", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_risk_metrics\n-- Description: Calculate risk metrics for portfolios\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Multiple window functions with same partition\n-- 2. VaR calculation inefficiencies\n-- 3. Could pre-compute some metrics\n\nwith portfolio_returns as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_portfolio_returns_daily\n),\n\n-- ISSUE: Multiple passes for different risk calculations\nwith_risk_metrics as (\n    select\n        portfolio_id,\n        valuation_date,\n        daily_return_mod_dietz as daily_return,\n        nav_usd,\n        -- ISSUE: Repeated window frame definitions\n        -- Max drawdown components\n        max(nav_usd) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between unbounded preceding and current row\n        ) as running_max_nav,\n        -- Downside deviation\n        sqrt(avg(\n            case when daily_return_mod_dietz < 0 then power(daily_return_mod_dietz, 2) else 0 end\n        ) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 251 preceding and current row\n        )) * sqrt(252) as downside_deviation_1y,\n        -- Sortino components\n        avg(daily_return_mod_dietz) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 251 preceding and current row\n        ) * 252 as annualized_return_1y,\n        volatility_1y\n    from portfolio_returns\n),\n\n-- ISSUE: Another CTE for derived metrics\nwith_derived as (\n    select\n        *,\n        -- Drawdown\n        (nav_usd - running_max_nav) / nullif(running_max_nav, 0) as drawdown,\n        -- Sortino ratio (assuming 0% risk-free)\n        case\n            when downside_deviation_1y > 0\n            then annualized_return_1y / downside_deviation_1y\n            else null\n        end as sortino_ratio,\n        -- Sharpe ratio (assuming 0% risk-free)\n        case\n            when volatility_1y > 0\n            then annualized_return_1y / volatility_1y\n            else null\n        end as sharpe_ratio\n    from with_risk_metrics\n),\n\n-- ISSUE: Max drawdown calculation\nwith_max_drawdown as (\n    select\n        *,\n        min(drawdown) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between unbounded preceding and current row\n        ) as max_drawdown\n    from with_derived\n),\n\n-- ISSUE: VaR calculation (simplified parametric)\nfinal as (\n    select\n        *,\n        -- Parametric VaR (95%)\n        nav_usd * volatility_1y / sqrt(252) * 1.645 as var_95_1d,\n        -- Parametric VaR (99%)\n        nav_usd * volatility_1y / sqrt(252) * 2.326 as var_99_1d\n    from with_max_drawdown\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_risk_metrics", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.550242Z", "completed_at": "2026-01-29T16:53:49.558246Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.558625Z", "completed_at": "2026-01-29T16:53:50.186037Z"}], "thread_id": "Thread-2", "execution_time": 0.6369268894195557, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e320007316a"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_trades_enriched", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: int_trades_enriched\n-- Description: Intermediate model enriching trades with security and price data\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Multiple heavy joins done row-by-row\n-- 2. Price lookup repeated for every trade\n-- 3. Could pre-aggregate before joining\n\nwith trades as (\n    select * from DBT_DEMO.DEV_pipeline_b.stg_trades\n),\n\nsecurities as (\n    select * from DBT_DEMO.DEV_pipeline_b.stg_securities\n),\n\nmarket_prices as (\n    select * from DBT_DEMO.DEV_pipeline_b.stg_market_prices\n),\n\nbrokers as (\n    select * from DBT_DEMO.DEV_pipeline_b.stg_brokers\n),\n\n-- ISSUE: Heavy multi-way join before any aggregation\nenriched as (\n    select\n        t.trade_id,\n        t.portfolio_id,\n        t.security_id,\n        t.trade_date,\n        t.settlement_date,\n        t.trade_type,\n        t.trade_category,\n        t.trade_size_bucket,\n        t.quantity,\n        t.price as execution_price,\n        t.gross_amount,\n        t.commission,\n        t.fees,\n        t.net_amount,\n        t.currency,\n        t.settlement_days,\n        t.trade_month,\n        t.trade_quarter,\n        t.trade_year,\n        -- Security attributes\n        s.ticker,\n        s.security_name,\n        s.security_type_standardized as security_type,\n        s.asset_class,\n        s.sector,\n        s.industry,\n        -- Broker attributes\n        b.broker_name,\n        b.broker_type,\n        b.region as broker_region,\n        b.commission_rate as standard_commission_rate,\n        -- Market price on trade date\n        mp.close_price as market_close_price,\n        mp.ma_20,\n        mp.ma_50,\n        mp.volatility_20d,\n        mp.trend_signal,\n        mp.volume_signal,\n        -- ISSUE: These calculations done per row\n        case\n            when mp.close_price > 0\n            then (t.price - mp.close_price) / mp.close_price * 100\n            else null\n        end as execution_vs_close_pct,\n        case\n            when t.price > mp.close_price then 'ABOVE_MARKET'\n            when t.price < mp.close_price then 'BELOW_MARKET'\n            else 'AT_MARKET'\n        end as execution_quality,\n        -- Cost analysis\n        t.commission + t.fees as total_costs,\n        case\n            when t.gross_amount > 0\n            then (t.commission + t.fees) / t.gross_amount * 10000\n            else null\n        end as cost_bps\n    from trades t\n    inner join securities s\n        on t.security_id = s.security_id\n    left join brokers b\n        on t.broker_id = b.broker_id\n    left join market_prices mp\n        on t.security_id = mp.security_id\n        and t.trade_date = mp.price_date\n)\n\nselect * from enriched", "relation_name": "DBT_DEMO.DEV_pipeline_b.int_trades_enriched", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:50.016175Z", "completed_at": "2026-01-29T16:53:50.022435Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:50.022890Z", "completed_at": "2026-01-29T16:53:50.781272Z"}], "thread_id": "Thread-3", "execution_time": 0.7662768363952637, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e320007316e"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_sector_attribution", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_sector_attribution\n-- Description: Aggregate attribution to sector level\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Re-aggregation of position data\n-- 2. Complex grouping logic\n-- 3. Could be combined with position attribution\n\nwith position_attribution as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_position_attribution\n),\n\n-- ISSUE: Aggregation that could be pushed upstream\nsector_daily as (\n    select\n        portfolio_id,\n        position_date,\n        sector,\n        count(distinct security_id) as position_count,\n        sum(market_value_usd) as sector_market_value,\n        sum(weight_pct) as sector_weight,\n        sum(contribution_to_return) as sector_contribution,\n        sum(allocation_effect) as sector_allocation_effect,\n        sum(position_pnl) as sector_pnl,\n        avg(security_return) as avg_security_return\n    from position_attribution\n    group by 1, 2, 3\n),\n\n-- ISSUE: Window functions for rolling metrics\nwith_rolling as (\n    select\n        *,\n        sum(sector_contribution) over (\n            partition by portfolio_id, sector\n            order by position_date\n            rows between 29 preceding and current row\n        ) as sector_contribution_30d,\n        avg(sector_weight) over (\n            partition by portfolio_id, sector\n            order by position_date\n            rows between 29 preceding and current row\n        ) as avg_sector_weight_30d,\n        lag(sector_weight, 1) over (\n            partition by portfolio_id, sector\n            order by position_date\n        ) as prior_sector_weight\n    from sector_daily\n)\n\nselect * from with_rolling", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_sector_attribution", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:50.189444Z", "completed_at": "2026-01-29T16:53:50.193775Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:50.194129Z", "completed_at": "2026-01-29T16:53:50.822685Z"}], "thread_id": "Thread-2", "execution_time": 0.6341309547424316, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e320007209a"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_portfolio_vs_benchmark", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_portfolio_vs_benchmark\n-- Description: Compare portfolio returns to benchmark\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Re-joins data that could be joined once upstream\n-- 2. Excess return calculation repeated\n-- 3. Complex rolling calculations\n\nwith portfolio_returns as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_portfolio_returns_daily\n),\n\nbenchmark_aligned as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_benchmark_aligned\n    where is_primary = true\n),\n\n-- ISSUE: Another join that combines already-processed data\ncombined as (\n    select\n        pr.portfolio_id,\n        pr.valuation_date,\n        pr.nav,\n        pr.nav_usd,\n        pr.daily_return_mod_dietz as portfolio_daily_return,\n        pr.cumulative_return as portfolio_cumulative_return,\n        pr.return_1m as portfolio_return_1m,\n        pr.return_3m as portfolio_return_3m,\n        pr.return_1y as portfolio_return_1y,\n        pr.volatility_1y as portfolio_volatility,\n        ba.benchmark_id,\n        ba.benchmark_daily_return,\n        ba.benchmark_cumulative_return,\n        ba.benchmark_return_30d as benchmark_return_1m,\n        ba.benchmark_return_90d as benchmark_return_3m,\n        ba.benchmark_return_1y,\n        ba.benchmark_volatility\n    from portfolio_returns pr\n    left join benchmark_aligned ba\n        on pr.portfolio_id = ba.portfolio_id\n        and pr.valuation_date = ba.valuation_date\n),\n\n-- ISSUE: Excess return calculations\nwith_excess as (\n    select\n        *,\n        portfolio_daily_return - coalesce(benchmark_daily_return, 0) as daily_excess_return,\n        portfolio_cumulative_return - coalesce(benchmark_cumulative_return, 0) as cumulative_excess_return,\n        portfolio_return_1m - coalesce(benchmark_return_1m, 0) as excess_return_1m,\n        portfolio_return_3m - coalesce(benchmark_return_3m, 0) as excess_return_3m,\n        portfolio_return_1y - coalesce(benchmark_return_1y, 0) as excess_return_1y\n    from combined\n),\n\n-- ISSUE: Rolling tracking error calculation\nwith_tracking_error as (\n    select\n        *,\n        stddev(daily_excess_return) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 251 preceding and current row\n        ) * sqrt(252) as tracking_error_1y,\n        avg(daily_excess_return) over (\n            partition by portfolio_id\n            order by valuation_date\n            rows between 251 preceding and current row\n        ) * 252 as annualized_alpha\n    from with_excess\n),\n\n-- ISSUE: Information ratio\nfinal as (\n    select\n        *,\n        case\n            when tracking_error_1y > 0\n            then annualized_alpha / tracking_error_1y\n            else null\n        end as information_ratio\n    from with_tracking_error\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_portfolio_vs_benchmark", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:50.825986Z", "completed_at": "2026-01-29T16:53:50.830141Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:50.830447Z", "completed_at": "2026-01-29T16:53:51.337825Z"}], "thread_id": "Thread-2", "execution_time": 0.5127460956573486, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710c2"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_trade_pnl", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: int_trade_pnl\n-- Description: Calculate P&L for each trade\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Complex position tracking logic that could be simplified\n-- 2. Multiple self-joins for cost basis calculation\n-- 3. Window functions recalculated multiple times\n\nwith trades as (\n    select * from DBT_DEMO.DEV_pipeline_b.int_trades_enriched\n),\n\n-- ISSUE: Running position calculation done inefficiently\npositions as (\n    select\n        trade_id,\n        portfolio_id,\n        security_id,\n        ticker,\n        security_name,\n        security_type,\n        asset_class,\n        sector,\n        industry,\n        trade_date,\n        trade_type,\n        trade_category,\n        quantity,\n        execution_price,\n        net_amount,\n        commission,\n        -- ISSUE: Multiple window functions with same partition\n        sum(case\n            when trade_category = 'PURCHASE' then quantity\n            when trade_category = 'SALE' then -quantity\n            else 0\n        end) over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n            rows between unbounded preceding and current row\n        ) as running_position,\n        sum(case\n            when trade_category = 'PURCHASE' then net_amount\n            when trade_category = 'SALE' then -net_amount\n            else 0\n        end) over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n            rows between unbounded preceding and current row\n        ) as cumulative_cost,\n        -- ISSUE: Another separate window for purchase-only\n        sum(case when trade_category = 'PURCHASE' then quantity else 0 end) over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n            rows between unbounded preceding and current row\n        ) as cumulative_purchased_qty,\n        sum(case when trade_category = 'PURCHASE' then net_amount else 0 end) over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n            rows between unbounded preceding and current row\n        ) as cumulative_purchase_cost\n    from trades\n),\n\n-- ISSUE: Separate CTE for cost basis\nwith_cost_basis as (\n    select\n        *,\n        case\n            when cumulative_purchased_qty > 0\n            then cumulative_purchase_cost / cumulative_purchased_qty\n            else null\n        end as avg_cost_basis\n    from positions\n),\n\n-- ISSUE: Another pass for realized P&L\nwith_pnl as (\n    select\n        *,\n        case\n            when trade_category = 'SALE' and avg_cost_basis is not null\n            then (execution_price - avg_cost_basis) * quantity\n            else null\n        end as realized_pnl,\n        case\n            when trade_category = 'SALE' and avg_cost_basis is not null and avg_cost_basis > 0\n            then (execution_price - avg_cost_basis) / avg_cost_basis * 100\n            else null\n        end as realized_pnl_pct\n    from with_cost_basis\n)\n\nselect * from with_pnl", "relation_name": "DBT_DEMO.DEV_pipeline_b.int_trade_pnl", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.665218Z", "completed_at": "2026-01-29T16:53:49.670970Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.671336Z", "completed_at": "2026-01-29T16:53:52.091048Z"}], "thread_id": "Thread-4", "execution_time": 2.4268009662628174, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e3200072096"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_position_snapshot", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: fact_position_snapshot\n-- Description: Position-level fact table with attribution\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Heavy joins that duplicate upstream work\n-- 2. Could be more selective in columns\n\nwith position_attribution as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_position_attribution\n),\n\nportfolios as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_portfolios\n),\n\n-- ISSUE: Re-joining portfolio data\nfinal as (\n    select\n        md5(cast(coalesce(cast(pa.portfolio_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(pa.security_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(pa.position_date as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as position_snapshot_key,\n        p.portfolio_name,\n        p.portfolio_type,\n        p.fund_id,\n        pa.portfolio_id,\n        pa.security_id,\n        pa.position_date,\n        pa.ticker,\n        pa.security_type,\n        pa.asset_class,\n        pa.sector,\n        pa.industry,\n        pa.quantity,\n        pa.market_value_usd,\n        pa.weight_pct,\n        pa.close_price,\n        pa.ma_20,\n        pa.ma_50,\n        pa.volatility_20d,\n        pa.security_return,\n        pa.contribution_to_return,\n        pa.allocation_effect,\n        pa.position_pnl,\n        -- ISSUE: More date extractions\n        extract(year from pa.position_date) as position_year,\n        extract(month from pa.position_date) as position_month,\n        date_trunc('month', pa.position_date) as position_month_start\n    from position_attribution pa\n    inner join portfolios p\n        on pa.portfolio_id = p.portfolio_id\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_c.fact_position_snapshot", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:49.062530Z", "completed_at": "2026-01-29T16:53:49.077852Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:49.078889Z", "completed_at": "2026-01-29T16:53:52.119263Z"}], "thread_id": "Thread-1", "execution_time": 3.057898998260498, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e320007208e"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_cashflow_summary", "compiled": true, "compiled_code": "-- Pipeline A: Simple Cashflow Pipeline\n-- Model: fact_cashflow_summary\n-- Description: Fact table summarizing cashflows by portfolio and month\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Self-joins for prior period comparisons (should use LAG)\n-- 2. Late aggregation (aggregates after full join)\n-- 3. Repeated window functions with same partitions\n-- 4. Redundant date calculations per row\n-- 5. Correlated subqueries for fund-level totals\n\nwith cashflows as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_cashflows\n),\n\nportfolios as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_portfolios\n),\n\n-- ISSUE: Full join before aggregation (scans all rows)\njoined as (\n    select\n        c.cashflow_id,\n        c.portfolio_id,\n        p.portfolio_name,\n        p.portfolio_type,\n        p.fund_id,\n        c.cashflow_type,\n        c.cashflow_date,\n        c.amount,\n        c.currency,\n        -- ISSUE: Redundant date calculations done per row\n        date_trunc('month', c.cashflow_date) as cashflow_month,\n        date_trunc('quarter', c.cashflow_date) as cashflow_quarter,\n        date_trunc('year', c.cashflow_date) as cashflow_year,\n        extract(year from c.cashflow_date) as year_num,\n        extract(month from c.cashflow_date) as month_num,\n        extract(quarter from c.cashflow_date) as quarter_num,\n        extract(dayofmonth from c.cashflow_date) as day_num\n    from cashflows c\n    inner join portfolios p\n        on c.portfolio_id = p.portfolio_id\n),\n\n-- ISSUE: Aggregation happens after full row-level join\naggregated as (\n    select\n        portfolio_id,\n        portfolio_name,\n        portfolio_type,\n        fund_id,\n        cashflow_month,\n        cashflow_quarter,\n        cashflow_year,\n        year_num,\n        month_num,\n        quarter_num,\n        cashflow_type,\n        currency,\n        count(*) as transaction_count,\n        count(distinct cashflow_id) as unique_transactions,\n        sum(amount) as total_amount,\n        avg(amount) as avg_amount,\n        min(amount) as min_amount,\n        max(amount) as max_amount,\n        stddev(amount) as stddev_amount,\n        -- ISSUE: Percentile calculations (slow)\n        percentile_cont(0.25) within group (order by amount) as p25_amount,\n        percentile_cont(0.50) within group (order by amount) as median_amount,\n        percentile_cont(0.75) within group (order by amount) as p75_amount\n    from joined\n    group by 1,2,3,4,5,6,7,8,9,10,11,12  -- ISSUE: Non-descriptive GROUP BY\n),\n\n-- ISSUE: Self-join for prior month comparisons (should use LAG)\nwith_prior_months as (\n    select\n        agg.*,\n        -- ISSUE: Self-join for prior month\n        agg_m1.total_amount as prior_1m_total,\n        agg_m1.transaction_count as prior_1m_count,\n        -- ISSUE: Self-join for 3 months ago\n        agg_m3.total_amount as prior_3m_total,\n        -- ISSUE: Self-join for 6 months ago\n        agg_m6.total_amount as prior_6m_total,\n        -- ISSUE: Self-join for 12 months ago\n        agg_m12.total_amount as prior_12m_total\n    from aggregated agg\n    left join aggregated agg_m1\n        on agg.portfolio_id = agg_m1.portfolio_id\n        and agg.cashflow_type = agg_m1.cashflow_type\n        and agg.currency = agg_m1.currency\n        and agg_m1.cashflow_month = dateadd(month, -1, agg.cashflow_month)\n    left join aggregated agg_m3\n        on agg.portfolio_id = agg_m3.portfolio_id\n        and agg.cashflow_type = agg_m3.cashflow_type\n        and agg.currency = agg_m3.currency\n        and agg_m3.cashflow_month = dateadd(month, -3, agg.cashflow_month)\n    left join aggregated agg_m6\n        on agg.portfolio_id = agg_m6.portfolio_id\n        and agg.cashflow_type = agg_m6.cashflow_type\n        and agg.currency = agg_m6.currency\n        and agg_m6.cashflow_month = dateadd(month, -6, agg.cashflow_month)\n    left join aggregated agg_m12\n        on agg.portfolio_id = agg_m12.portfolio_id\n        and agg.cashflow_type = agg_m12.cashflow_type\n        and agg.currency = agg_m12.currency\n        and agg_m12.cashflow_month = dateadd(month, -12, agg.cashflow_month)\n),\n\n-- ISSUE: Multiple window functions with repeated partitions\nwith_window_calcs as (\n    select\n        wpm.*,\n        -- ISSUE: Running totals (repeated partition)\n        sum(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between unbounded preceding and current row\n        ) as cumulative_total,\n        sum(transaction_count) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between unbounded preceding and current row\n        ) as cumulative_count,\n        -- ISSUE: Moving averages (same partition repeated)\n        avg(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between 2 preceding and current row\n        ) as rolling_3m_avg,\n        avg(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between 5 preceding and current row\n        ) as rolling_6m_avg,\n        avg(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between 11 preceding and current row\n        ) as rolling_12m_avg,\n        -- ISSUE: More window calculations\n        stddev(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between 11 preceding and current row\n        ) as rolling_12m_stddev,\n        min(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between 11 preceding and current row\n        ) as rolling_12m_min,\n        max(total_amount) over (\n            partition by wpm.portfolio_id, wpm.cashflow_type, wpm.currency\n            order by wpm.cashflow_month\n            rows between 11 preceding and current row\n        ) as rolling_12m_max\n    from with_prior_months wpm\n),\n\n-- ISSUE: Correlated subqueries for fund-level context (very slow)\nwith_fund_context as (\n    select\n        wwc.*,\n        -- ISSUE: Correlated subquery for fund total\n        (\n            select sum(total_amount)\n            from aggregated agg2\n            inner join portfolios p2\n                on agg2.portfolio_id = p2.portfolio_id\n            where p2.fund_id = wwc.fund_id\n            and agg2.cashflow_month = wwc.cashflow_month\n            and agg2.cashflow_type = wwc.cashflow_type\n        ) as fund_total_amount,\n        -- ISSUE: Another correlated subquery for portfolio count\n        (\n            select count(distinct agg2.portfolio_id)\n            from aggregated agg2\n            inner join portfolios p2\n                on agg2.portfolio_id = p2.portfolio_id\n            where p2.fund_id = wwc.fund_id\n            and agg2.cashflow_month = wwc.cashflow_month\n            and agg2.cashflow_type = wwc.cashflow_type\n        ) as fund_portfolio_count\n    from with_window_calcs wwc\n),\n\n-- ISSUE: Complex derived metrics with repeated CASE statements\nfinal as (\n    select\n        md5(cast(coalesce(cast(wfc.portfolio_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(wfc.cashflow_month as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(wfc.cashflow_type as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(wfc.currency as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as cashflow_summary_key,\n        wfc.*,\n        -- ISSUE: Portfolio share of fund (repeated division)\n        case\n            when wfc.fund_total_amount > 0\n            then (wfc.total_amount / wfc.fund_total_amount) * 100\n            else null\n        end as portfolio_share_of_fund_pct,\n        -- ISSUE: Month-over-month growth calculations\n        case\n            when wfc.prior_1m_total is not null and wfc.prior_1m_total != 0\n            then ((wfc.total_amount - wfc.prior_1m_total) / abs(wfc.prior_1m_total)) * 100\n            else null\n        end as mom_growth_pct,\n        case\n            when wfc.prior_3m_total is not null and wfc.prior_3m_total != 0\n            then ((wfc.total_amount - wfc.prior_3m_total) / abs(wfc.prior_3m_total)) * 100\n            else null\n        end as growth_3m_pct,\n        case\n            when wfc.prior_12m_total is not null and wfc.prior_12m_total != 0\n            then ((wfc.total_amount - wfc.prior_12m_total) / abs(wfc.prior_12m_total)) * 100\n            else null\n        end as yoy_growth_pct,\n        -- ISSUE: Trend classification (complex nested CASE)\n        case\n            when wfc.rolling_3m_avg > wfc.rolling_12m_avg * 1.3 then 'ACCELERATING'\n            when wfc.rolling_3m_avg > wfc.rolling_12m_avg * 1.1 then 'GROWING'\n            when wfc.rolling_3m_avg < wfc.rolling_12m_avg * 0.7 then 'DECLINING_FAST'\n            when wfc.rolling_3m_avg < wfc.rolling_12m_avg * 0.9 then 'DECLINING'\n            else 'STABLE'\n        end as trend_classification,\n        -- ISSUE: Volatility classification\n        case\n            when wfc.rolling_12m_stddev < wfc.rolling_12m_avg * 0.1 then 'LOW_VOLATILITY'\n            when wfc.rolling_12m_stddev < wfc.rolling_12m_avg * 0.3 then 'MODERATE_VOLATILITY'\n            when wfc.rolling_12m_stddev < wfc.rolling_12m_avg * 0.5 then 'HIGH_VOLATILITY'\n            else 'VERY_HIGH_VOLATILITY'\n        end as volatility_classification,\n        -- ISSUE: Size classification (repeated CASE)\n        case\n            when abs(wfc.total_amount) >= 10000000 then 'MEGA'\n            when abs(wfc.total_amount) >= 5000000 then 'LARGE'\n            when abs(wfc.total_amount) >= 1000000 then 'MEDIUM'\n            when abs(wfc.total_amount) >= 100000 then 'SMALL'\n            else 'MICRO'\n        end as transaction_size_category\n    from with_fund_context wfc\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_a.fact_cashflow_summary", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:50.786713Z", "completed_at": "2026-01-29T16:53:50.793995Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:50.794442Z", "completed_at": "2026-01-29T16:53:51.647748Z"}], "thread_id": "Thread-3", "execution_time": 0.8623940944671631, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e320007209e"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.int_fund_rollup", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: int_fund_rollup\n-- Description: Roll up portfolio metrics to fund level\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Recursive-like hierarchy traversal\n-- 2. Multiple aggregation levels\n-- 3. Heavy joins\n\nwith fund_hierarchy as (\n    select * from DBT_DEMO.DEV_pipeline_c.stg_fund_hierarchy\n),\n\nportfolios as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_portfolios\n),\n\nrisk_metrics as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_risk_metrics\n),\n\n-- Get portfolio to fund mapping\nportfolio_fund_map as (\n    select\n        p.portfolio_id,\n        p.portfolio_name,\n        p.fund_id,\n        fh.entity_name as fund_name,\n        fh.parent_entity_id,\n        fh.hierarchy_level\n    from portfolios p\n    left join fund_hierarchy fh\n        on p.fund_id = fh.entity_id\n),\n\n-- Get latest risk metrics per portfolio\nlatest_metrics as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (partition by portfolio_id order by valuation_date desc) as rn\n        from risk_metrics\n    )\n    where rn = 1  -- ISSUE: Should use QUALIFY\n),\n\n-- ISSUE: Join and aggregate\nfund_aggregated as (\n    select\n        pfm.fund_id,\n        pfm.fund_name,\n        pfm.parent_entity_id,\n        pfm.hierarchy_level,\n        lm.valuation_date,\n        count(distinct pfm.portfolio_id) as portfolio_count,\n        sum(lm.nav_usd) as total_nav_usd,\n        -- Weighted average metrics\n        sum(lm.nav_usd * lm.annualized_return_1y) / nullif(sum(lm.nav_usd), 0) as weighted_return_1y,\n        sum(lm.nav_usd * lm.volatility_1y) / nullif(sum(lm.nav_usd), 0) as weighted_volatility_1y,\n        sum(lm.nav_usd * lm.sharpe_ratio) / nullif(sum(lm.nav_usd), 0) as weighted_sharpe_ratio,\n        min(lm.max_drawdown) as worst_drawdown,\n        sum(lm.var_95_1d) as total_var_95\n    from portfolio_fund_map pfm\n    inner join latest_metrics lm\n        on pfm.portfolio_id = lm.portfolio_id\n    group by 1, 2, 3, 4, 5\n)\n\nselect * from fund_aggregated", "relation_name": "DBT_DEMO.DEV_pipeline_c.int_fund_rollup", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:51.343035Z", "completed_at": "2026-01-29T16:53:51.352588Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:51.353016Z", "completed_at": "2026-01-29T16:53:53.861300Z"}], "thread_id": "Thread-2", "execution_time": 2.5194051265716553, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e3200073172"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_sector_performance", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: fact_sector_performance\n-- Description: Sector-level performance aggregation\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Re-aggregates data from upstream\n-- 2. Complex window functions\n\nwith sector_attribution as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_sector_attribution\n),\n\nportfolios as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_portfolios\n),\n\n-- ISSUE: Another portfolio join\nwith_portfolio_info as (\n    select\n        sa.*,\n        p.portfolio_name,\n        p.portfolio_type,\n        p.fund_id\n    from sector_attribution sa\n    inner join portfolios p\n        on sa.portfolio_id = p.portfolio_id\n),\n\n-- ISSUE: More window functions for sector ranking\nwith_rankings as (\n    select\n        *,\n        rank() over (\n            partition by portfolio_id, position_date\n            order by sector_weight desc\n        ) as sector_weight_rank,\n        rank() over (\n            partition by portfolio_id, position_date\n            order by sector_contribution desc\n        ) as sector_contribution_rank\n    from with_portfolio_info\n),\n\nfinal as (\n    select\n        md5(cast(coalesce(cast(portfolio_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sector as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(position_date as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as sector_performance_key,\n        *,\n        case\n            when sector_weight_rank <= 3 then 'TOP_3'\n            when sector_weight_rank <= 5 then 'TOP_5'\n            else 'OTHER'\n        end as sector_weight_tier\n    from with_rankings\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_c.fact_sector_performance", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:52.759661Z", "completed_at": "2026-01-29T16:53:52.768777Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:52.769209Z", "completed_at": "2026-01-29T16:53:53.973148Z"}], "thread_id": "Thread-1", "execution_time": 1.2227981090545654, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-7654-0003-1e3200073176"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.report_monthly_cashflows", "compiled": true, "compiled_code": "-- Pipeline A: Simple Cashflow Pipeline\n-- Model: report_monthly_cashflows\n-- Description: LP reporting view for monthly cashflow analysis\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Re-aggregates data that's already in fact table\n-- 2. Repeated window functions\n-- 3. Suboptimal pivot pattern\n\nwith fact_data as (\n    select * from DBT_DEMO.DEV_pipeline_a.fact_cashflow_summary\n),\n\n-- ISSUE: Re-aggregating already aggregated data\nmonthly_totals as (\n    select\n        portfolio_id,\n        portfolio_name,\n        portfolio_type,\n        fund_id,\n        cashflow_month,\n        year_num,\n        month_num,\n        sum(case when cashflow_type = 'CONTRIBUTION' then total_amount else 0 end) as contributions,\n        sum(case when cashflow_type = 'DISTRIBUTION' then total_amount else 0 end) as distributions,\n        sum(case when cashflow_type = 'DIVIDEND' then total_amount else 0 end) as dividends,\n        sum(case when cashflow_type = 'FEE' then total_amount else 0 end) as fees,\n        sum(total_amount) as total_cashflow,\n        sum(transaction_count) as total_transactions\n    from fact_data\n    group by 1,2,3,4,5,6,7\n),\n\n-- ISSUE: Window functions recalculated multiple times\nwith_running_totals as (\n    select\n        *,\n        -- Running totals (repeated pattern)\n        sum(contributions) over (\n            partition by portfolio_id\n            order by cashflow_month\n            rows between unbounded preceding and current row\n        ) as cumulative_contributions,\n        sum(distributions) over (\n            partition by portfolio_id\n            order by cashflow_month\n            rows between unbounded preceding and current row\n        ) as cumulative_distributions,\n        sum(total_cashflow) over (\n            partition by portfolio_id\n            order by cashflow_month\n            rows between unbounded preceding and current row\n        ) as cumulative_net_cashflow,\n        -- Prior period comparisons (another repeated pattern)\n        lag(contributions, 1) over (partition by portfolio_id order by cashflow_month) as prior_month_contributions,\n        lag(distributions, 1) over (partition by portfolio_id order by cashflow_month) as prior_month_distributions,\n        lag(total_cashflow, 1) over (partition by portfolio_id order by cashflow_month) as prior_month_total,\n        -- YoY comparison\n        lag(contributions, 12) over (partition by portfolio_id order by cashflow_month) as prior_year_contributions,\n        lag(distributions, 12) over (partition by portfolio_id order by cashflow_month) as prior_year_distributions\n    from monthly_totals\n),\n\n-- ISSUE: Calculated columns that could be simplified\nfinal as (\n    select\n        *,\n        contributions - coalesce(prior_month_contributions, 0) as mom_contribution_change,\n        distributions - coalesce(prior_month_distributions, 0) as mom_distribution_change,\n        case\n            when prior_year_contributions > 0\n            then (contributions - prior_year_contributions) / prior_year_contributions * 100\n            else null\n        end as yoy_contribution_pct_change,\n        contributions - distributions as net_inflow\n    from with_running_totals\n)\n\nselect * from final\norder by portfolio_id, cashflow_month", "relation_name": "DBT_DEMO.DEV_pipeline_a.report_monthly_cashflows", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:53.864872Z", "completed_at": "2026-01-29T16:53:53.871168Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:53.871510Z", "completed_at": "2026-01-29T16:53:57.927500Z"}], "thread_id": "Thread-2", "execution_time": 4.063572883605957, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710ca"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_fund_summary", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: fact_fund_summary\n-- Description: Fund-level summary metrics\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Based on already-aggregated data\n-- 2. Could push more logic upstream\n\nwith fund_rollup as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_fund_rollup\n),\n\nfund_hierarchy as (\n    select * from DBT_DEMO.DEV_pipeline_c.stg_fund_hierarchy\n),\n\n-- Get parent fund info\nwith_parent as (\n    select\n        fr.*,\n        parent.entity_name as parent_fund_name\n    from fund_rollup fr\n    left join fund_hierarchy parent\n        on fr.parent_entity_id = parent.entity_id\n),\n\nfinal as (\n    select\n        md5(cast(coalesce(cast(fund_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(valuation_date as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as fund_summary_key,\n        fund_id,\n        fund_name,\n        parent_entity_id as parent_fund_id,\n        parent_fund_name,\n        hierarchy_level,\n        valuation_date,\n        portfolio_count,\n        total_nav_usd,\n        weighted_return_1y,\n        weighted_volatility_1y,\n        weighted_sharpe_ratio,\n        worst_drawdown,\n        total_var_95,\n        -- ISSUE: Calculated fields\n        case\n            when weighted_return_1y >= 0.15 then 'HIGH'\n            when weighted_return_1y >= 0.08 then 'MEDIUM'\n            when weighted_return_1y >= 0 then 'LOW'\n            else 'NEGATIVE'\n        end as return_tier,\n        case\n            when weighted_sharpe_ratio >= 1.5 then 'EXCELLENT'\n            when weighted_sharpe_ratio >= 1.0 then 'GOOD'\n            when weighted_sharpe_ratio >= 0.5 then 'FAIR'\n            else 'POOR'\n        end as risk_adjusted_tier\n    from with_parent\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_c.fact_fund_summary", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:52.763055Z", "completed_at": "2026-01-29T16:53:52.773514Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:52.776648Z", "completed_at": "2026-01-29T16:54:03.468714Z"}], "thread_id": "Thread-3", "execution_time": 10.717077016830444, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765b-0003-1e32000710c6"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_portfolio_positions", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: fact_portfolio_positions\n-- Description: Current position snapshot by portfolio and security\n-- DEPENDENCY: Uses fact_cashflow_summary from Pipeline A for portfolio cash context\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Gets latest position via subquery (should use QUALIFY)\n-- 2. Self-joins for historical position lookups\n-- 3. Correlated subqueries for portfolio-level aggregations\n-- 4. Repeated window functions\n\nwith trade_pnl as (\n    select * from DBT_DEMO.DEV_pipeline_b.int_trade_pnl\n),\n\n-- DEPENDENCY ON PIPELINE A: Get cashflow context for each portfolio\ncashflow_summary as (\n    select * from DBT_DEMO.DEV_pipeline_a.fact_cashflow_summary\n),\n\n-- Aggregate cashflows by portfolio to get total contributions/distributions\nportfolio_cashflows as (\n    select\n        portfolio_id,\n        sum(case when cashflow_type = 'CONTRIBUTION' then cumulative_total else 0 end) as total_contributions,\n        sum(case when cashflow_type = 'DISTRIBUTION' then abs(cumulative_total) else 0 end) as total_distributions,\n        max(cashflow_month) as last_cashflow_date\n    from cashflow_summary\n    group by portfolio_id\n),\n\nlatest_positions as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (\n                partition by portfolio_id, security_id\n                order by trade_date desc, trade_id desc\n            ) as rn\n        from trade_pnl\n    )\n    where rn = 1\n),\n\n-- ISSUE: Self-join to get position 30 days ago\npositions_30d_ago as (\n    select\n        portfolio_id,\n        security_id,\n        running_position as position_30d_ago,\n        avg_cost_basis as cost_basis_30d_ago\n    from (\n        select\n            *,\n            row_number() over (\n                partition by portfolio_id, security_id\n                order by trade_date desc, trade_id desc\n            ) as rn\n        from trade_pnl\n        where trade_date <= dateadd(day, -30, current_date())\n    )\n    where rn = 1\n),\n\n-- ISSUE: Self-join to get position 90 days ago\npositions_90d_ago as (\n    select\n        portfolio_id,\n        security_id,\n        running_position as position_90d_ago,\n        avg_cost_basis as cost_basis_90d_ago\n    from (\n        select\n            *,\n            row_number() over (\n                partition by portfolio_id, security_id\n                order by trade_date desc, trade_id desc\n            ) as rn\n        from trade_pnl\n        where trade_date <= dateadd(day, -90, current_date())\n    )\n    where rn = 1\n),\n\nmarket_prices as (\n    select\n        security_id,\n        close_price as current_price,\n        price_date\n    from (\n        select\n            security_id,\n            close_price,\n            price_date,\n            row_number() over (partition by security_id order by price_date desc) as rn\n        from DBT_DEMO.DEV_pipeline_b.stg_market_prices\n    )\n    where rn = 1  -- ISSUE: Again, should use QUALIFY\n),\n\n-- ISSUE: Get historical prices for comparison\nmarket_prices_30d_ago as (\n    select\n        security_id,\n        close_price as price_30d_ago\n    from (\n        select\n            security_id,\n            close_price,\n            row_number() over (partition by security_id order by price_date desc) as rn\n        from DBT_DEMO.DEV_pipeline_b.stg_market_prices\n        where price_date <= dateadd(day, -30, current_date())\n    )\n    where rn = 1\n),\n\n-- ISSUE: Join all the position snapshots together\nenriched_positions as (\n    select\n        lp.*,\n        mp.current_price,\n        mp.price_date as price_as_of_date,\n        p30.position_30d_ago,\n        p30.cost_basis_30d_ago,\n        p90.position_90d_ago,\n        p90.cost_basis_90d_ago,\n        mp30.price_30d_ago,\n        pcf.total_contributions,\n        pcf.total_distributions,\n        pcf.last_cashflow_date\n    from latest_positions lp\n    left join market_prices mp\n        on lp.security_id = mp.security_id\n    left join positions_30d_ago p30\n        on lp.portfolio_id = p30.portfolio_id\n        and lp.security_id = p30.security_id\n    left join positions_90d_ago p90\n        on lp.portfolio_id = p90.portfolio_id\n        and lp.security_id = p90.security_id\n    left join market_prices_30d_ago mp30\n        on lp.security_id = mp30.security_id\n    left join portfolio_cashflows pcf\n        on lp.portfolio_id = pcf.portfolio_id\n    where lp.running_position != 0\n),\n\n-- ISSUE: Window functions for portfolio-level context\nwith_portfolio_context as (\n    select\n        ep.*,\n        -- ISSUE: Repeated partition by portfolio_id\n        sum(ep.running_position * ep.current_price) over (\n            partition by ep.portfolio_id\n        ) as portfolio_total_market_value,\n        sum(ep.running_position * ep.avg_cost_basis) over (\n            partition by ep.portfolio_id\n        ) as portfolio_total_cost_basis,\n        count(*) over (\n            partition by ep.portfolio_id\n        ) as portfolio_position_count,\n        -- ISSUE: Rankings\n        row_number() over (\n            partition by ep.portfolio_id\n            order by (ep.running_position * ep.current_price) desc\n        ) as position_size_rank,\n        row_number() over (\n            partition by ep.portfolio_id\n            order by ((ep.current_price - ep.avg_cost_basis) / nullif(ep.avg_cost_basis, 0)) desc\n        ) as position_return_rank\n    from enriched_positions ep\n),\n\n-- ISSUE: Separate aggregation for sector context (should use window functions)\nsector_aggs as (\n    select\n        portfolio_id,\n        sector,\n        sum(running_position * current_price) as sector_market_value,\n        count(*) as sector_position_count\n    from enriched_positions\n    group by 1, 2\n),\n\nwith_sector_context as (\n    select\n        wpc.*,\n        sa.sector_market_value,\n        sa.sector_position_count\n    from with_portfolio_context wpc\n    left join sector_aggs sa\n        on wpc.portfolio_id = sa.portfolio_id\n        and wpc.sector = sa.sector\n),\n\n-- ISSUE: Complex calculations in final select\nfinal as (\n    select\n        md5(cast(coalesce(cast(wsc.portfolio_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(wsc.security_id as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as position_key,\n        wsc.portfolio_id,\n        wsc.security_id,\n        wsc.ticker,\n        wsc.security_name,\n        wsc.sector,\n        wsc.asset_class,\n        wsc.running_position as current_quantity,\n        wsc.avg_cost_basis,\n        wsc.current_price,\n        wsc.price_as_of_date,\n        -- Core calculations\n        wsc.running_position * wsc.avg_cost_basis as cost_basis_value,\n        wsc.running_position * wsc.current_price as market_value,\n        (wsc.running_position * wsc.current_price) - (wsc.running_position * wsc.avg_cost_basis) as unrealized_pnl,\n        -- ISSUE: Repeated division logic\n        case\n            when wsc.avg_cost_basis > 0\n            then ((wsc.current_price - wsc.avg_cost_basis) / wsc.avg_cost_basis) * 100\n            else null\n        end as unrealized_pnl_pct,\n        -- Portfolio context\n        wsc.portfolio_total_market_value,\n        wsc.portfolio_total_cost_basis,\n        wsc.portfolio_position_count,\n        -- ISSUE: Weight calculation (repeated division)\n        case\n            when wsc.portfolio_total_market_value > 0\n            then ((wsc.running_position * wsc.current_price) / wsc.portfolio_total_market_value) * 100\n            else null\n        end as portfolio_weight_pct,\n        -- Sector context\n        wsc.sector_market_value,\n        wsc.sector_position_count,\n        case\n            when wsc.sector_market_value > 0\n            then ((wsc.running_position * wsc.current_price) / wsc.sector_market_value) * 100\n            else null\n        end as sector_weight_pct,\n        -- Historical comparison\n        wsc.position_30d_ago,\n        wsc.position_90d_ago,\n        wsc.position_30d_ago - wsc.running_position as position_change_30d,\n        wsc.position_90d_ago - wsc.running_position as position_change_90d,\n        -- Price momentum\n        wsc.price_30d_ago,\n        case\n            when wsc.price_30d_ago > 0\n            then ((wsc.current_price - wsc.price_30d_ago) / wsc.price_30d_ago) * 100\n            else null\n        end as price_change_30d_pct,\n        -- Cashflow context from Pipeline A\n        wsc.total_contributions,\n        wsc.total_distributions,\n        wsc.last_cashflow_date,\n        -- Rankings\n        wsc.position_size_rank,\n        wsc.position_return_rank,\n        -- ISSUE: Complex classification\n        case\n            when ((wsc.running_position * wsc.current_price) / nullif(wsc.portfolio_total_market_value, 0)) > 0.10 then 'CONCENTRATED'\n            when ((wsc.running_position * wsc.current_price) / nullif(wsc.portfolio_total_market_value, 0)) > 0.05 then 'SIGNIFICANT'\n            when ((wsc.running_position * wsc.current_price) / nullif(wsc.portfolio_total_market_value, 0)) > 0.02 then 'MODERATE'\n            else 'SMALL'\n        end as position_size_category,\n        wsc.cumulative_purchase_cost as total_invested,\n        current_timestamp() as snapshot_timestamp\n    from with_sector_context wsc\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_b.fact_portfolio_positions", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:53:52.752714Z", "completed_at": "2026-01-29T16:53:52.773189Z"}, {"name": "execute", "started_at": "2026-01-29T16:53:52.773935Z", "completed_at": "2026-01-29T16:54:24.012504Z"}], "thread_id": "Thread-4", "execution_time": 31.26361608505249, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f35-0001-765d-0003-1e32000720a2"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_trade_summary", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: fact_trade_summary\n-- Description: Fact table for trade-level analysis\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Self-joins for prior trade lookups (should use LAG)\n-- 2. Repeated window functions with same partitions\n-- 3. Correlated subqueries for security-level aggregations\n-- 4. Complex CASE statements repeated multiple times\n\nwith trade_pnl as (\n    select * from DBT_DEMO.DEV_pipeline_b.int_trade_pnl\n),\n\n-- ISSUE: Getting portfolio data again (already available through joins upstream)\nportfolios as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_portfolios\n),\n\n-- ISSUE: Join that adds overhead\nenriched as (\n    select\n        t.trade_id,\n        t.portfolio_id,\n        p.portfolio_name,\n        p.portfolio_type,\n        p.fund_id,\n        t.security_id,\n        t.ticker,\n        t.security_name,\n        t.security_type,\n        t.asset_class,\n        t.sector,\n        t.trade_date,\n        t.trade_type,\n        t.trade_category,\n        t.quantity,\n        t.execution_price,\n        t.net_amount,\n        t.commission,\n        t.running_position,\n        t.avg_cost_basis,\n        t.realized_pnl,\n        t.realized_pnl_pct,\n        -- ISSUE: Redundant date extractions (already done upstream)\n        extract(year from t.trade_date) as trade_year,\n        extract(month from t.trade_date) as trade_month,\n        extract(quarter from t.trade_date) as trade_quarter,\n        extract(dayofweek from t.trade_date) as trade_day_of_week,\n        date_trunc('week', t.trade_date) as trade_week,\n        date_trunc('month', t.trade_date) as trade_month_start\n    from trade_pnl t\n    left join portfolios p\n        on t.portfolio_id = p.portfolio_id\n),\n\n-- ISSUE: Self-joins for prior trade comparisons (should use LAG)\n-- Pre-compute trade sequence for self-join lookups\ntrade_sequences as (\n    select\n        *,\n        row_number() over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n        ) as trade_seq\n    from enriched\n),\n\nwith_prior_trades as (\n    select\n        ts.*,\n        -- ISSUE: Self-join for prior trade same security (should use LAG)\n        ts_prior.execution_price as prior_trade_price,\n        ts_prior.trade_date as prior_trade_date,\n        ts_prior.quantity as prior_trade_quantity,\n        -- ISSUE: Self-join for 5 trades ago (should use LAG offset)\n        ts_5.execution_price as price_5_trades_ago,\n        -- ISSUE: Self-join for 10 trades ago (should use LAG offset)\n        ts_10.execution_price as price_10_trades_ago\n    from trade_sequences ts\n    left join trade_sequences ts_prior\n        on ts.portfolio_id = ts_prior.portfolio_id\n        and ts.security_id = ts_prior.security_id\n        and ts_prior.trade_seq = ts.trade_seq - 1\n    left join trade_sequences ts_5\n        on ts.portfolio_id = ts_5.portfolio_id\n        and ts.security_id = ts_5.security_id\n        and ts_5.trade_seq = ts.trade_seq - 5\n    left join trade_sequences ts_10\n        on ts.portfolio_id = ts_10.portfolio_id\n        and ts.security_id = ts_10.security_id\n        and ts_10.trade_seq = ts.trade_seq - 10\n),\n\n-- ISSUE: Multiple window functions with repeated partitions\nwith_window_calcs as (\n    select\n        wpt.*,\n        -- ISSUE: Running aggregations (repeated partition by portfolio_id, security_id)\n        sum(quantity) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between unbounded preceding and current row\n        ) as cumulative_quantity,\n        sum(abs(net_amount)) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between unbounded preceding and current row\n        ) as cumulative_trade_value,\n        sum(coalesce(realized_pnl, 0)) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between unbounded preceding and current row\n        ) as cumulative_realized_pnl,\n        -- ISSUE: Moving averages (same partition repeated)\n        avg(execution_price) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between 4 preceding and current row\n        ) as rolling_5_trade_avg_price,\n        avg(execution_price) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between 9 preceding and current row\n        ) as rolling_10_trade_avg_price,\n        avg(execution_price) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between 19 preceding and current row\n        ) as rolling_20_trade_avg_price,\n        -- ISSUE: More window calculations\n        stddev(execution_price) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between 9 preceding and current row\n        ) as rolling_10_trade_price_stddev,\n        count(*) over (\n            partition by wpt.portfolio_id, wpt.security_id\n            order by wpt.trade_date, wpt.trade_id\n            rows between unbounded preceding and current row\n        ) as trade_sequence_number,\n        -- ISSUE: Rankings (same partition again)\n        row_number() over (\n            partition by wpt.portfolio_id, wpt.security_id, wpt.trade_category\n            order by abs(wpt.net_amount) desc\n        ) as size_rank_within_category\n    from with_prior_trades wpt\n),\n\n-- ISSUE: Separate CTE for running trade stats (should be combined with window calcs above)\nsecurity_trade_aggs as (\n    select\n        portfolio_id,\n        security_id,\n        trade_date,\n        trade_id,\n        -- ISSUE: These window functions duplicate the partition from with_window_calcs\n        count(*) over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n            rows between unbounded preceding and current row\n        ) as total_portfolio_trades_this_security,\n        avg(execution_price) over (\n            partition by portfolio_id, security_id\n            order by trade_date, trade_id\n            rows between unbounded preceding and current row\n        ) as avg_portfolio_price_this_security\n    from enriched\n),\n\n-- ISSUE: Separate aggregation for fund-level volume (should be combined upstream)\nfund_daily_volume as (\n    select\n        fund_id,\n        security_id,\n        trade_date,\n        sum(abs(net_amount)) as fund_total_volume_same_security_same_day\n    from enriched\n    group by 1, 2, 3\n),\n\nwith_security_context as (\n    select\n        wwc.*,\n        sta.total_portfolio_trades_this_security,\n        sta.avg_portfolio_price_this_security,\n        fdv.fund_total_volume_same_security_same_day\n    from with_window_calcs wwc\n    left join security_trade_aggs sta\n        on wwc.portfolio_id = sta.portfolio_id\n        and wwc.security_id = sta.security_id\n        and wwc.trade_id = sta.trade_id\n    left join fund_daily_volume fdv\n        on wwc.fund_id = fdv.fund_id\n        and wwc.security_id = fdv.security_id\n        and wwc.trade_date = fdv.trade_date\n),\n\n-- ISSUE: Complex derived metrics with repeated CASE statements\nfinal as (\n    select\n        md5(cast(coalesce(cast(wsc.trade_id as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as trade_key,\n        wsc.*,\n        -- ISSUE: Price change calculations (repeated division logic)\n        case\n            when wsc.prior_trade_price is not null and wsc.prior_trade_price > 0\n            then ((wsc.execution_price - wsc.prior_trade_price) / wsc.prior_trade_price) * 100\n            else null\n        end as price_change_from_prior_pct,\n        case\n            when wsc.price_5_trades_ago is not null and wsc.price_5_trades_ago > 0\n            then ((wsc.execution_price - wsc.price_5_trades_ago) / wsc.price_5_trades_ago) * 100\n            else null\n        end as price_change_from_5_trades_ago_pct,\n        case\n            when wsc.rolling_20_trade_avg_price is not null and wsc.rolling_20_trade_avg_price > 0\n            then ((wsc.execution_price - wsc.rolling_20_trade_avg_price) / wsc.rolling_20_trade_avg_price) * 100\n            else null\n        end as deviation_from_20_trade_avg_pct,\n        -- ISSUE: Trade size classification (repeated CASE)\n        case\n            when abs(wsc.net_amount) >= 10000000 then 'BLOCK_TRADE'\n            when abs(wsc.net_amount) >= 1000000 then 'LARGE'\n            when abs(wsc.net_amount) >= 100000 then 'MEDIUM'\n            when abs(wsc.net_amount) >= 10000 then 'SMALL'\n            else 'MICRO'\n        end as trade_size_category,\n        -- ISSUE: Trade timing classification (complex nested CASE)\n        case\n            when wsc.execution_price > wsc.rolling_10_trade_avg_price * 1.1 then 'BOUGHT_HIGH'\n            when wsc.execution_price > wsc.rolling_10_trade_avg_price * 1.03 then 'ABOVE_AVERAGE'\n            when wsc.execution_price < wsc.rolling_10_trade_avg_price * 0.9 then 'BOUGHT_LOW'\n            when wsc.execution_price < wsc.rolling_10_trade_avg_price * 0.97 then 'BELOW_AVERAGE'\n            else 'AVERAGE'\n        end as execution_quality,\n        -- ISSUE: Momentum signal (repeated logic)\n        case\n            when wsc.rolling_5_trade_avg_price > wsc.rolling_20_trade_avg_price then 'UPTREND'\n            when wsc.rolling_5_trade_avg_price < wsc.rolling_20_trade_avg_price then 'DOWNTREND'\n            else 'NEUTRAL'\n        end as price_momentum,\n        -- ISSUE: Volatility classification\n        case\n            when wsc.rolling_10_trade_price_stddev < wsc.rolling_10_trade_avg_price * 0.02 then 'LOW_VOLATILITY'\n            when wsc.rolling_10_trade_price_stddev < wsc.rolling_10_trade_avg_price * 0.05 then 'MODERATE_VOLATILITY'\n            when wsc.rolling_10_trade_price_stddev < wsc.rolling_10_trade_avg_price * 0.10 then 'HIGH_VOLATILITY'\n            else 'VERY_HIGH_VOLATILITY'\n        end as price_volatility_regime,\n        -- ISSUE: Trade frequency indicator\n        case\n            when wsc.trade_sequence_number >= 100 then 'VERY_ACTIVE'\n            when wsc.trade_sequence_number >= 50 then 'ACTIVE'\n            when wsc.trade_sequence_number >= 20 then 'MODERATE'\n            when wsc.trade_sequence_number >= 5 then 'LIGHT'\n            else 'FIRST_FEW_TRADES'\n        end as trading_activity_level\n    from with_security_context wsc\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_b.fact_trade_summary", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:54:24.032942Z", "completed_at": "2026-01-29T16:54:24.039781Z"}, {"name": "execute", "started_at": "2026-01-29T16:54:24.040541Z", "completed_at": "2026-01-29T16:54:26.398395Z"}], "thread_id": "Thread-2", "execution_time": 2.3776869773864746, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f36-0001-765b-0003-1e32000710ce"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.report_trading_performance", "compiled": true, "compiled_code": "-- Pipeline B: Trade Analytics Pipeline\n-- Model: report_trading_performance\n-- Description: Trading performance report for IC dashboard\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Re-aggregates fact data that could be pre-computed\n-- 2. Complex window functions repeated from other models\n-- 3. Multiple CTEs that could be consolidated\n\nwith trades as (\n    select * from DBT_DEMO.DEV_pipeline_b.fact_trade_summary\n),\n\npositions as (\n    select * from DBT_DEMO.DEV_pipeline_b.fact_portfolio_positions\n),\n\n-- ISSUE: Re-aggregating trade data by portfolio/month\ntrade_metrics as (\n    select\n        portfolio_id,\n        portfolio_name,\n        portfolio_type,\n        fund_id,\n        trade_year,\n        trade_month,\n        count(distinct trade_id) as trade_count,\n        count(distinct security_id) as securities_traded,\n        sum(case when trade_category = 'PURCHASE' then 1 else 0 end) as buy_count,\n        sum(case when trade_category = 'SALE' then 1 else 0 end) as sell_count,\n        sum(case when trade_category = 'PURCHASE' then net_amount else 0 end) as total_purchases,\n        sum(case when trade_category = 'SALE' then abs(net_amount) else 0 end) as total_sales,\n        sum(coalesce(realized_pnl, 0)) as total_realized_pnl,\n        avg(case when realized_pnl is not null then realized_pnl_pct else null end) as avg_realized_return_pct\n    from trades\n    group by 1,2,3,4,5,6\n),\n\n-- ISSUE: Aggregating positions separately\nposition_metrics as (\n    select\n        portfolio_id,\n        count(distinct security_id) as position_count,\n        sum(market_value) as total_market_value,\n        sum(cost_basis_value) as total_cost_basis,\n        sum(unrealized_pnl) as total_unrealized_pnl,\n        avg(unrealized_pnl_pct) as avg_unrealized_return_pct\n    from positions\n    group by 1\n),\n\n-- ISSUE: Window functions for running totals (repeated pattern)\nwith_running_totals as (\n    select\n        tm.*,\n        sum(total_realized_pnl) over (\n            partition by tm.portfolio_id\n            order by tm.trade_year, tm.trade_month\n            rows between unbounded preceding and current row\n        ) as cumulative_realized_pnl,\n        sum(total_purchases) over (\n            partition by tm.portfolio_id\n            order by tm.trade_year, tm.trade_month\n            rows between unbounded preceding and current row\n        ) as cumulative_invested,\n        -- ISSUE: Multiple LAG functions\n        lag(total_realized_pnl, 1) over (\n            partition by tm.portfolio_id\n            order by tm.trade_year, tm.trade_month\n        ) as prior_month_pnl,\n        lag(trade_count, 1) over (\n            partition by tm.portfolio_id\n            order by tm.trade_year, tm.trade_month\n        ) as prior_month_trades\n    from trade_metrics tm\n),\n\n-- ISSUE: Final join adds more complexity\nfinal as (\n    select\n        wrt.*,\n        pm.position_count,\n        pm.total_market_value,\n        pm.total_cost_basis,\n        pm.total_unrealized_pnl,\n        pm.avg_unrealized_return_pct,\n        -- Combined metrics\n        wrt.total_realized_pnl + coalesce(pm.total_unrealized_pnl, 0) as total_pnl,\n        case\n            when pm.total_cost_basis > 0\n            then ((pm.total_market_value + wrt.cumulative_realized_pnl) - pm.total_cost_basis) / pm.total_cost_basis * 100\n            else null\n        end as total_return_pct\n    from with_running_totals wrt\n    left join position_metrics pm\n        on wrt.portfolio_id = pm.portfolio_id\n)\n\nselect * from final\norder by portfolio_id, trade_year, trade_month", "relation_name": "DBT_DEMO.DEV_pipeline_b.report_trading_performance", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:54:24.022617Z", "completed_at": "2026-01-29T16:54:24.040170Z"}, {"name": "execute", "started_at": "2026-01-29T16:54:24.044871Z", "completed_at": "2026-01-29T16:54:38.795044Z"}], "thread_id": "Thread-1", "execution_time": 14.775132179260254, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f36-0001-7654-0003-1e320007317a"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.fact_portfolio_performance", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: fact_portfolio_performance\n-- Description: Main performance fact table\n-- DEPENDENCIES:\n--   - Pipeline A: fact_cashflow_summary (for cashflow context)\n--   - Pipeline B: fact_trade_summary, fact_portfolio_positions (for trading/position context)\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Multiple self-joins for period comparisons\n-- 2. Repeated window functions with same partitions\n-- 3. Complex CASE statements repeated multiple times\n-- 4. Correlated subqueries\n-- 5. Late filtering and unnecessary full table scans\n\nwith portfolio_vs_benchmark as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_portfolio_vs_benchmark\n),\n\nrisk_metrics as (\n    select * from DBT_DEMO.DEV_pipeline_c.int_risk_metrics\n),\n\nportfolios as (\n    select * from DBT_DEMO.DEV_pipeline_a.stg_portfolios\n),\n\n-- DEPENDENCY ON PIPELINE A: Cashflow summary for capital deployment context\ncashflow_summary as (\n    select * from DBT_DEMO.DEV_pipeline_a.fact_cashflow_summary\n),\n\n-- Aggregate cashflows to portfolio level\nportfolio_cashflow_totals as (\n    select\n        portfolio_id,\n        sum(case when cashflow_type = 'CONTRIBUTION' then cumulative_total else 0 end) as total_contributions,\n        sum(case when cashflow_type = 'DISTRIBUTION' then abs(cumulative_total) else 0 end) as total_distributions,\n        sum(cumulative_total) as net_cashflow\n    from cashflow_summary\n    group by portfolio_id\n),\n\n-- DEPENDENCY ON PIPELINE B: Trade summary for trading activity context\ntrade_summary as (\n    select * from DBT_DEMO.DEV_pipeline_b.fact_trade_summary\n),\n\n-- Aggregate trades to portfolio/date level\nportfolio_trade_activity as (\n    select\n        portfolio_id,\n        trade_month_start as activity_month,\n        count(*) as trade_count,\n        sum(case when trade_category = 'PURCHASE' then abs(net_amount) else 0 end) as total_purchases,\n        sum(case when trade_category = 'SALE' then abs(net_amount) else 0 end) as total_sales,\n        sum(coalesce(realized_pnl, 0)) as realized_pnl\n    from trade_summary\n    group by portfolio_id, trade_month_start\n),\n\n-- DEPENDENCY ON PIPELINE B: Position snapshot for current holdings context\nportfolio_positions as (\n    select * from DBT_DEMO.DEV_pipeline_b.fact_portfolio_positions\n),\n\n-- Aggregate positions to portfolio level\nportfolio_position_totals as (\n    select\n        portfolio_id,\n        sum(market_value) as total_market_value,\n        sum(cost_basis_value) as total_cost_basis,\n        sum(unrealized_pnl) as total_unrealized_pnl,\n        count(*) as position_count\n    from portfolio_positions\n    group by portfolio_id\n),\n\n-- ISSUE: Another join when data could flow from upstream\ncombined as (\n    select\n        pvb.portfolio_id,\n        pvb.valuation_date,\n        pvb.nav,\n        pvb.nav_usd,\n        -- Portfolio returns\n        pvb.portfolio_daily_return,\n        pvb.portfolio_cumulative_return,\n        pvb.portfolio_return_1m,\n        pvb.portfolio_return_3m,\n        pvb.portfolio_return_1y,\n        pvb.portfolio_volatility,\n        -- Benchmark comparison\n        pvb.benchmark_id,\n        pvb.benchmark_daily_return,\n        pvb.benchmark_cumulative_return,\n        pvb.benchmark_return_1m,\n        pvb.benchmark_return_3m,\n        pvb.benchmark_return_1y,\n        pvb.benchmark_volatility,\n        -- Relative performance\n        pvb.daily_excess_return,\n        pvb.cumulative_excess_return,\n        pvb.excess_return_1m,\n        pvb.excess_return_3m,\n        pvb.excess_return_1y,\n        pvb.tracking_error_1y,\n        pvb.annualized_alpha,\n        pvb.information_ratio,\n        -- Risk metrics\n        rm.drawdown,\n        rm.max_drawdown,\n        rm.downside_deviation_1y,\n        rm.sharpe_ratio,\n        rm.sortino_ratio,\n        rm.var_95_1d,\n        rm.var_99_1d\n    from portfolio_vs_benchmark pvb\n    inner join risk_metrics rm\n        on pvb.portfolio_id = rm.portfolio_id\n        and pvb.valuation_date = rm.valuation_date\n),\n\n-- ISSUE: Self-join for prior period comparisons (should use LAG)\nwith_prior_periods as (\n    select\n        c.*,\n        -- ISSUE: Self-join for 1 day ago\n        c1d.nav_usd as nav_1d_ago,\n        c1d.portfolio_cumulative_return as return_1d_ago,\n        -- ISSUE: Self-join for 1 week ago\n        c1w.nav_usd as nav_1w_ago,\n        c1w.portfolio_cumulative_return as return_1w_ago,\n        -- ISSUE: Self-join for 1 month ago\n        c1m.nav_usd as nav_1m_ago,\n        c1m.portfolio_cumulative_return as return_1m_ago,\n        -- ISSUE: Self-join for 3 months ago\n        c3m.nav_usd as nav_3m_ago,\n        c3m.portfolio_cumulative_return as return_3m_ago,\n        -- ISSUE: Self-join for 1 year ago\n        c1y.nav_usd as nav_1y_ago,\n        c1y.portfolio_cumulative_return as return_1y_ago\n    from combined c\n    left join combined c1d\n        on c.portfolio_id = c1d.portfolio_id\n        and c1d.valuation_date = dateadd(day, -1, c.valuation_date)\n    left join combined c1w\n        on c.portfolio_id = c1w.portfolio_id\n        and c1w.valuation_date = dateadd(day, -7, c.valuation_date)\n    left join combined c1m\n        on c.portfolio_id = c1m.portfolio_id\n        and c1m.valuation_date = dateadd(month, -1, c.valuation_date)\n    left join combined c3m\n        on c.portfolio_id = c3m.portfolio_id\n        and c3m.valuation_date = dateadd(month, -3, c.valuation_date)\n    left join combined c1y\n        on c.portfolio_id = c1y.portfolio_id\n        and c1y.valuation_date = dateadd(year, -1, c.valuation_date)\n),\n\n-- ISSUE: Multiple window functions with repeated partitions\nwith_rankings as (\n    select\n        wpp.*,\n        -- ISSUE: Multiple ROW_NUMBER with same partition\n        row_number() over (\n            partition by wpp.portfolio_id\n            order by wpp.portfolio_cumulative_return desc\n        ) as best_performance_rank,\n        row_number() over (\n            partition by wpp.portfolio_id\n            order by wpp.portfolio_cumulative_return asc\n        ) as worst_performance_rank,\n        row_number() over (\n            partition by wpp.portfolio_id\n            order by wpp.sharpe_ratio desc nulls last\n        ) as best_sharpe_rank,\n        -- ISSUE: DENSE_RANK with same partition\n        dense_rank() over (\n            partition by wpp.portfolio_id\n            order by wpp.nav_usd desc\n        ) as nav_size_rank,\n        -- ISSUE: More window calculations\n        avg(wpp.portfolio_daily_return) over (\n            partition by wpp.portfolio_id\n            order by wpp.valuation_date\n            rows between 20 preceding and current row\n        ) as rolling_20d_avg_return,\n        avg(wpp.portfolio_daily_return) over (\n            partition by wpp.portfolio_id\n            order by wpp.valuation_date\n            rows between 60 preceding and current row\n        ) as rolling_60d_avg_return,\n        stddev(wpp.portfolio_daily_return) over (\n            partition by wpp.portfolio_id\n            order by wpp.valuation_date\n            rows between 20 preceding and current row\n        ) as rolling_20d_volatility,\n        stddev(wpp.portfolio_daily_return) over (\n            partition by wpp.portfolio_id\n            order by wpp.valuation_date\n            rows between 60 preceding and current row\n        ) as rolling_60d_volatility\n    from with_prior_periods wpp\n),\n\n-- ISSUE: Complex derived metrics with repeated CASE statements\nwith_derived_metrics as (\n    select\n        wr.*,\n        -- ISSUE: Repeated complex CASE for performance classification\n        case\n            when wr.portfolio_cumulative_return >= 0.50 then 'EXCEPTIONAL'\n            when wr.portfolio_cumulative_return >= 0.30 then 'EXCELLENT'\n            when wr.portfolio_cumulative_return >= 0.15 then 'VERY_GOOD'\n            when wr.portfolio_cumulative_return >= 0.05 then 'GOOD'\n            when wr.portfolio_cumulative_return >= 0.00 then 'NEUTRAL'\n            when wr.portfolio_cumulative_return >= -0.05 then 'POOR'\n            when wr.portfolio_cumulative_return >= -0.15 then 'VERY_POOR'\n            else 'UNACCEPTABLE'\n        end as performance_rating,\n        -- ISSUE: Same CASE for risk classification\n        case\n            when wr.sharpe_ratio >= 3.0 then 'EXCEPTIONAL'\n            when wr.sharpe_ratio >= 2.0 then 'EXCELLENT'\n            when wr.sharpe_ratio >= 1.5 then 'VERY_GOOD'\n            when wr.sharpe_ratio >= 1.0 then 'GOOD'\n            when wr.sharpe_ratio >= 0.5 then 'NEUTRAL'\n            when wr.sharpe_ratio >= 0.0 then 'POOR'\n            else 'VERY_POOR'\n        end as risk_adjusted_rating,\n        -- ISSUE: Complex calculation repeated\n        case\n            when wr.nav_1m_ago is not null and wr.nav_1m_ago > 0\n            then (wr.nav_usd - wr.nav_1m_ago) / wr.nav_1m_ago\n            else null\n        end as nav_change_1m_pct,\n        case\n            when wr.nav_3m_ago is not null and wr.nav_3m_ago > 0\n            then (wr.nav_usd - wr.nav_3m_ago) / wr.nav_3m_ago\n            else null\n        end as nav_change_3m_pct,\n        case\n            when wr.nav_1y_ago is not null and wr.nav_1y_ago > 0\n            then (wr.nav_usd - wr.nav_1y_ago) / wr.nav_1y_ago\n            else null\n        end as nav_change_1y_pct,\n        -- ISSUE: Momentum indicators with repeated logic\n        case\n            when wr.rolling_20d_avg_return > wr.rolling_60d_avg_return then 'POSITIVE_MOMENTUM'\n            when wr.rolling_20d_avg_return < wr.rolling_60d_avg_return then 'NEGATIVE_MOMENTUM'\n            else 'NEUTRAL_MOMENTUM'\n        end as momentum_signal,\n        -- ISSUE: Volatility regime classification\n        case\n            when wr.rolling_20d_volatility > wr.rolling_60d_volatility * 1.5 then 'HIGH_VOLATILITY'\n            when wr.rolling_20d_volatility > wr.rolling_60d_volatility * 1.2 then 'ELEVATED_VOLATILITY'\n            when wr.rolling_20d_volatility < wr.rolling_60d_volatility * 0.8 then 'LOW_VOLATILITY'\n            else 'NORMAL_VOLATILITY'\n        end as volatility_regime\n    from with_rankings wr\n),\n\n-- ISSUE: Separate peer aggregation CTEs (should use window functions with partition by portfolio_type)\npeer_return_aggs as (\n    select\n        p2.portfolio_type,\n        pvb2.valuation_date,\n        avg(pvb2.portfolio_cumulative_return) as peer_avg_return\n    from portfolio_vs_benchmark pvb2\n    inner join portfolios p2\n        on pvb2.portfolio_id = p2.portfolio_id\n    group by 1, 2\n),\n\npeer_sharpe_aggs as (\n    select\n        p2.portfolio_type,\n        rm2.valuation_date,\n        percentile_cont(0.5) within group (order by rm2.sharpe_ratio) as peer_median_sharpe\n    from risk_metrics rm2\n    inner join portfolios p2\n        on rm2.portfolio_id = p2.portfolio_id\n    group by 1, 2\n),\n\nwith_peer_comparison as (\n    select\n        wdm.*,\n        pra.peer_avg_return,\n        psa.peer_median_sharpe\n    from with_derived_metrics wdm\n    inner join portfolios p_self\n        on wdm.portfolio_id = p_self.portfolio_id\n    left join peer_return_aggs pra\n        on p_self.portfolio_type = pra.portfolio_type\n        and wdm.valuation_date = pra.valuation_date\n    left join peer_sharpe_aggs psa\n        on p_self.portfolio_type = psa.portfolio_type\n        and wdm.valuation_date = psa.valuation_date\n),\n\n-- ISSUE: Portfolio attributes added last\nfinal as (\n    select\n        md5(cast(coalesce(cast(wpc.portfolio_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(wpc.valuation_date as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as performance_key,\n        p.portfolio_name,\n        p.portfolio_type,\n        p.fund_id,\n        wpc.*,\n        -- ISSUE: Date dimensions recalculated (should be in dim table)\n        extract(year from wpc.valuation_date) as valuation_year,\n        extract(month from wpc.valuation_date) as valuation_month,\n        extract(quarter from wpc.valuation_date) as valuation_quarter,\n        extract(dayofweek from wpc.valuation_date) as valuation_day_of_week,\n        extract(dayofyear from wpc.valuation_date) as valuation_day_of_year,\n        date_trunc('month', wpc.valuation_date) as valuation_month_start,\n        date_trunc('quarter', wpc.valuation_date) as valuation_quarter_start,\n        date_trunc('year', wpc.valuation_date) as valuation_year_start,\n        -- ISSUE: String concatenations (slow)\n        concat(p.portfolio_name, ' - ', wpc.valuation_date::varchar) as display_name,\n        concat('Q', extract(quarter from wpc.valuation_date), ' ', extract(year from wpc.valuation_date)) as quarter_label,\n        -- ISSUE: Complex derived field\n        case\n            when wpc.portfolio_cumulative_return > wpc.peer_avg_return then 'OUTPERFORMING'\n            when wpc.portfolio_cumulative_return < wpc.peer_avg_return then 'UNDERPERFORMING'\n            else 'AT_PEER'\n        end as peer_relative_performance\n    from with_peer_comparison wpc\n    inner join portfolios p\n        on wpc.portfolio_id = p.portfolio_id\n)\n\nselect * from final", "relation_name": "DBT_DEMO.DEV_pipeline_c.fact_portfolio_performance", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:54:38.802123Z", "completed_at": "2026-01-29T16:54:38.813695Z"}, {"name": "execute", "started_at": "2026-01-29T16:54:38.817477Z", "completed_at": "2026-01-29T16:54:40.301398Z"}], "thread_id": "Thread-4", "execution_time": 1.5010266304016113, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f36-0001-765b-0003-1e32000710d2"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.report_ic_dashboard", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: report_ic_dashboard\n-- Description: Investment Committee dashboard report\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Combines multiple fact tables\n-- 2. Re-aggregates aggregated data\n-- 3. Complex pivoting logic\n-- 4. Multiple CTEs that could be simplified\n\nwith portfolio_performance as (\n    select * from DBT_DEMO.DEV_pipeline_c.fact_portfolio_performance\n),\n\nfund_summary as (\n    select * from DBT_DEMO.DEV_pipeline_c.fact_fund_summary\n),\n\nposition_snapshot as (\n    select * from DBT_DEMO.DEV_pipeline_c.fact_position_snapshot\n),\n\n-- ISSUE: Get latest performance per portfolio\nlatest_portfolio_perf as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (\n                partition by portfolio_id\n                order by valuation_date desc\n            ) as rn\n        from portfolio_performance\n    )\n    where rn = 1  -- ISSUE: Should use QUALIFY\n),\n\n-- ISSUE: Get latest positions per portfolio\nlatest_positions as (\n    select *\n    from (\n        select\n            *,\n            row_number() over (\n                partition by portfolio_id, security_id\n                order by position_date desc\n            ) as rn\n        from position_snapshot\n    )\n    where rn = 1\n),\n\n-- ISSUE: Re-aggregate positions for portfolio summary\nposition_summary as (\n    select\n        portfolio_id,\n        count(distinct security_id) as total_positions,\n        count(distinct sector) as sector_count,\n        sum(market_value_usd) as total_market_value,\n        max(weight_pct) as max_position_weight,\n        -- Concentration metrics\n        sum(case when weight_pct >= 0.05 then 1 else 0 end) as positions_over_5pct\n    from latest_positions\n    group by 1\n),\n\n-- ISSUE: Sector concentration\nsector_concentration as (\n    select\n        portfolio_id,\n        listagg(sector, ', ') within group (order by sector_weight desc) as top_sectors\n    from (\n        select\n            portfolio_id,\n            sector,\n            sum(weight_pct) as sector_weight,\n            row_number() over (partition by portfolio_id order by sum(weight_pct) desc) as sector_rank\n        from latest_positions\n        group by 1, 2\n    )\n    where sector_rank <= 3\n    group by 1\n),\n\n-- ISSUE: Combine all metrics\ndashboard_data as (\n    select\n        lpp.portfolio_id,\n        lpp.portfolio_name,\n        lpp.portfolio_type,\n        lpp.fund_id,\n        fs.fund_name,\n        lpp.valuation_date as as_of_date,\n        lpp.nav_usd,\n        -- Performance\n        lpp.portfolio_return_1m,\n        lpp.portfolio_return_3m,\n        lpp.portfolio_return_1y,\n        lpp.portfolio_cumulative_return as inception_return,\n        -- Benchmark comparison\n        lpp.benchmark_id,\n        lpp.excess_return_1m,\n        lpp.excess_return_1y,\n        lpp.information_ratio,\n        -- Risk\n        lpp.portfolio_volatility,\n        lpp.sharpe_ratio,\n        lpp.sortino_ratio,\n        lpp.max_drawdown,\n        lpp.var_95_1d,\n        -- Positions\n        ps.total_positions,\n        ps.sector_count,\n        ps.max_position_weight,\n        ps.positions_over_5pct,\n        sc.top_sectors,\n        -- Fund level\n        fs.total_nav_usd as fund_total_nav,\n        fs.portfolio_count as fund_portfolio_count,\n        fs.weighted_sharpe_ratio as fund_sharpe,\n        -- Portfolio share of fund\n        case\n            when fs.total_nav_usd > 0\n            then lpp.nav_usd / fs.total_nav_usd * 100\n            else null\n        end as pct_of_fund\n    from latest_portfolio_perf lpp\n    left join fund_summary fs\n        on lpp.fund_id = fs.fund_id\n        and lpp.valuation_date = fs.valuation_date\n    left join position_summary ps\n        on lpp.portfolio_id = ps.portfolio_id\n    left join sector_concentration sc\n        on lpp.portfolio_id = sc.portfolio_id\n),\n\n-- ISSUE: Final scoring/ranking\nfinal as (\n    select\n        *,\n        -- Performance score (simplified)\n        (coalesce(portfolio_return_1y, 0) * 0.4 +\n         coalesce(sharpe_ratio, 0) * 0.3 +\n         coalesce(information_ratio, 0) * 0.3) as composite_score,\n        rank() over (order by portfolio_return_1y desc nulls last) as return_rank,\n        rank() over (order by sharpe_ratio desc nulls last) as sharpe_rank\n    from dashboard_data\n)\n\nselect * from final\norder by composite_score desc", "relation_name": "DBT_DEMO.DEV_pipeline_c.report_ic_dashboard", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2026-01-29T16:54:38.807308Z", "completed_at": "2026-01-29T16:54:38.813314Z"}, {"name": "execute", "started_at": "2026-01-29T16:54:38.814206Z", "completed_at": "2026-01-29T16:54:40.731363Z"}], "thread_id": "Thread-3", "execution_time": 1.9305078983306885, "adapter_response": {"_message": "SUCCESS 1", "code": "SUCCESS", "rows_affected": 1, "query_id": "01c20f36-0001-765d-0003-1e32000720a6"}, "message": "SUCCESS 1", "failures": null, "unique_id": "model.bain_capital_portfolio_analytics.report_lp_quarterly", "compiled": true, "compiled_code": "-- Pipeline C: Complex Portfolio Analytics\n-- Model: report_lp_quarterly\n-- Description: Quarterly LP reporting with period comparisons\n--\n-- ISSUES FOR ARTEMIS TO OPTIMIZE:\n-- 1. Self-joins for multi-period comparisons (should use LAG)\n-- 2. Repeated window functions with same partitions\n-- 3. Correlated subqueries for fund-level aggregations\n-- 4. Complex CASE statements repeated multiple times\n-- 5. Late filtering after heavy computation\n\nwith portfolio_performance as (\n    select * from DBT_DEMO.DEV_pipeline_c.fact_portfolio_performance\n),\n\ncashflow_summary as (\n    select * from DBT_DEMO.DEV_pipeline_a.fact_cashflow_summary\n),\n\n-- ISSUE: Filter to quarter-end dates only (filtering late)\nquarter_end_perf as (\n    select *\n    from portfolio_performance\n    where valuation_date = last_day(valuation_date, 'quarter')\n),\n\n-- ISSUE: Aggregate cashflows to quarterly\nquarterly_cashflows as (\n    select\n        portfolio_id,\n        date_trunc('quarter', cashflow_month) as quarter_start,\n        sum(case when cashflow_type = 'CONTRIBUTION' then total_amount else 0 end) as quarterly_contributions,\n        sum(case when cashflow_type = 'DISTRIBUTION' then total_amount else 0 end) as quarterly_distributions,\n        sum(case when cashflow_type = 'DIVIDEND' then total_amount else 0 end) as quarterly_dividends,\n        sum(case when cashflow_type = 'FEE' then abs(total_amount) else 0 end) as quarterly_fees,\n        sum(total_amount) as quarterly_net_cashflow,\n        count(distinct transaction_count) as total_transactions\n    from cashflow_summary\n    group by 1, 2\n),\n\n-- ISSUE: Join performance and cashflows\ncombined as (\n    select\n        qep.portfolio_id,\n        qep.portfolio_name,\n        qep.portfolio_type,\n        qep.fund_id,\n        qep.valuation_date as quarter_end,\n        qep.valuation_quarter_start as quarter_start,\n        qep.valuation_year,\n        qep.valuation_quarter,\n        qep.nav_usd,\n        qep.portfolio_return_3m as quarterly_return,\n        qep.portfolio_return_1y,\n        qep.portfolio_cumulative_return,\n        qep.benchmark_return_3m as benchmark_quarterly_return,\n        qep.excess_return_3m as quarterly_excess_return,\n        qep.sharpe_ratio,\n        qep.sortino_ratio,\n        qep.max_drawdown,\n        qep.performance_rating,\n        qep.risk_adjusted_rating,\n        qcf.quarterly_contributions,\n        qcf.quarterly_distributions,\n        qcf.quarterly_dividends,\n        qcf.quarterly_fees,\n        qcf.quarterly_net_cashflow,\n        qcf.total_transactions\n    from quarter_end_perf qep\n    left join quarterly_cashflows qcf\n        on qep.portfolio_id = qcf.portfolio_id\n        and qep.valuation_quarter_start = qcf.quarter_start\n),\n\n-- ISSUE: Multiple self-joins for historical comparisons (should use LAG)\nwith_self_joins as (\n    select\n        c.*,\n        -- ISSUE: Self-join for prior quarter\n        c_q1.nav_usd as prior_1q_nav,\n        c_q1.quarterly_return as prior_1q_return,\n        c_q1.sharpe_ratio as prior_1q_sharpe,\n        -- ISSUE: Self-join for 2 quarters ago\n        c_q2.nav_usd as prior_2q_nav,\n        c_q2.quarterly_return as prior_2q_return,\n        -- ISSUE: Self-join for 3 quarters ago\n        c_q3.nav_usd as prior_3q_nav,\n        c_q3.quarterly_return as prior_3q_return,\n        -- ISSUE: Self-join for 4 quarters ago (1 year)\n        c_q4.nav_usd as prior_4q_nav,\n        c_q4.quarterly_return as prior_4q_return,\n        c_q4.sharpe_ratio as prior_4q_sharpe,\n        -- ISSUE: Self-join for 8 quarters ago (2 years)\n        c_q8.nav_usd as prior_8q_nav,\n        c_q8.quarterly_return as prior_8q_return\n    from combined c\n    left join combined c_q1\n        on c.portfolio_id = c_q1.portfolio_id\n        and c_q1.quarter_end = dateadd(quarter, -1, c.quarter_end)\n    left join combined c_q2\n        on c.portfolio_id = c_q2.portfolio_id\n        and c_q2.quarter_end = dateadd(quarter, -2, c.quarter_end)\n    left join combined c_q3\n        on c.portfolio_id = c_q3.portfolio_id\n        and c_q3.quarter_end = dateadd(quarter, -3, c.quarter_end)\n    left join combined c_q4\n        on c.portfolio_id = c_q4.portfolio_id\n        and c_q4.quarter_end = dateadd(quarter, -4, c.quarter_end)\n    left join combined c_q8\n        on c.portfolio_id = c_q8.portfolio_id\n        and c_q8.quarter_end = dateadd(quarter, -8, c.quarter_end)\n),\n\n-- ISSUE: Multiple window functions with repeated partitions\nwith_window_calcs as (\n    select\n        wsj.*,\n        -- ISSUE: Running totals (repeated partition)\n        sum(quarterly_contributions) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between unbounded preceding and current row\n        ) as cumulative_contributions,\n        sum(quarterly_distributions) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between unbounded preceding and current row\n        ) as cumulative_distributions,\n        sum(quarterly_dividends) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between unbounded preceding and current row\n        ) as cumulative_dividends,\n        sum(quarterly_fees) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between unbounded preceding and current row\n        ) as cumulative_fees,\n        -- ISSUE: Moving averages (same partition repeated)\n        avg(quarterly_return) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between 3 preceding and current row\n        ) as rolling_4q_avg_return,\n        avg(quarterly_return) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between 7 preceding and current row\n        ) as rolling_8q_avg_return,\n        -- ISSUE: More window calculations\n        stddev(quarterly_return) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between 3 preceding and current row\n        ) as rolling_4q_volatility,\n        min(quarterly_return) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between 3 preceding and current row\n        ) as rolling_4q_min_return,\n        max(quarterly_return) over (\n            partition by wsj.portfolio_id\n            order by wsj.quarter_end\n            rows between 3 preceding and current row\n        ) as rolling_4q_max_return,\n        -- ISSUE: Ranking (same partition again)\n        row_number() over (\n            partition by wsj.portfolio_id\n            order by wsj.quarterly_return desc\n        ) as best_quarter_rank,\n        row_number() over (\n            partition by wsj.portfolio_id\n            order by wsj.quarterly_return asc\n        ) as worst_quarter_rank\n    from with_self_joins wsj\n),\n\n-- ISSUE: Separate fund-level aggregation (should use window functions)\nfund_quarterly_aggs as (\n    select\n        fund_id,\n        valuation_date as quarter_end,\n        sum(nav_usd) as fund_total_nav,\n        avg(portfolio_return_3m) as fund_avg_quarterly_return,\n        count(distinct portfolio_id) as fund_portfolio_count\n    from quarter_end_perf\n    group by 1, 2\n),\n\nwith_fund_context as (\n    select\n        wwc.*,\n        fqa.fund_total_nav,\n        fqa.fund_avg_quarterly_return,\n        fqa.fund_portfolio_count\n    from with_window_calcs wwc\n    left join fund_quarterly_aggs fqa\n        on wwc.fund_id = fqa.fund_id\n        and wwc.quarter_end = fqa.quarter_end\n),\n\n-- ISSUE: Complex derived metrics with repeated CASE statements\nwith_derived_metrics as (\n    select\n        wfc.*,\n        -- ISSUE: Portfolio weight in fund\n        case\n            when wfc.fund_total_nav > 0\n            then (wfc.nav_usd / wfc.fund_total_nav) * 100\n            else null\n        end as portfolio_weight_in_fund,\n        -- ISSUE: Complex QoQ calculations (repeated division logic)\n        case\n            when wfc.prior_1q_nav is not null and wfc.prior_1q_nav > 0\n            then ((wfc.nav_usd - wfc.prior_1q_nav) / wfc.prior_1q_nav) * 100\n            else null\n        end as qoq_nav_growth_pct,\n        case\n            when wfc.prior_1q_return is not null\n            then (wfc.quarterly_return - wfc.prior_1q_return)\n            else null\n        end as qoq_return_change,\n        -- ISSUE: Complex YoY calculations\n        case\n            when wfc.prior_4q_nav is not null and wfc.prior_4q_nav > 0\n            then ((wfc.nav_usd - wfc.prior_4q_nav) / wfc.prior_4q_nav) * 100\n            else null\n        end as yoy_nav_growth_pct,\n        case\n            when wfc.prior_4q_return is not null\n            then (wfc.quarterly_return - wfc.prior_4q_return)\n            else null\n        end as yoy_return_change,\n        -- ISSUE: 2-year growth\n        case\n            when wfc.prior_8q_nav is not null and wfc.prior_8q_nav > 0\n            then ((wfc.nav_usd - wfc.prior_8q_nav) / wfc.prior_8q_nav) * 100\n            else null\n        end as two_year_nav_growth_pct,\n        -- ISSUE: TVPI and DPI calculations (repeated division)\n        case\n            when wfc.cumulative_contributions > 0\n            then (wfc.nav_usd + wfc.cumulative_distributions) / wfc.cumulative_contributions\n            else null\n        end as tvpi,\n        case\n            when wfc.cumulative_contributions > 0\n            then wfc.cumulative_distributions / wfc.cumulative_contributions\n            else null\n        end as dpi,\n        case\n            when wfc.cumulative_contributions > 0\n            then wfc.nav_usd / wfc.cumulative_contributions\n            else null\n        end as rvpi,\n        -- ISSUE: Performance trend classification (complex nested CASE)\n        case\n            when wfc.rolling_4q_avg_return > wfc.rolling_8q_avg_return * 1.2 then 'ACCELERATING'\n            when wfc.rolling_4q_avg_return > wfc.rolling_8q_avg_return * 1.05 then 'IMPROVING'\n            when wfc.rolling_4q_avg_return < wfc.rolling_8q_avg_return * 0.8 then 'DECELERATING'\n            when wfc.rolling_4q_avg_return < wfc.rolling_8q_avg_return * 0.95 then 'DECLINING'\n            else 'STABLE'\n        end as performance_trend,\n        -- ISSUE: Consistency rating (complex nested CASE)\n        case\n            when wfc.rolling_4q_volatility < 0.02 then 'VERY_CONSISTENT'\n            when wfc.rolling_4q_volatility < 0.05 then 'CONSISTENT'\n            when wfc.rolling_4q_volatility < 0.10 then 'MODERATE'\n            when wfc.rolling_4q_volatility < 0.15 then 'VARIABLE'\n            else 'HIGHLY_VARIABLE'\n        end as consistency_rating,\n        -- ISSUE: Relative to fund performance (nested CASE)\n        case\n            when wfc.quarterly_return > wfc.fund_avg_quarterly_return + 0.05 then 'SIGNIFICANT_OUTPERFORM'\n            when wfc.quarterly_return > wfc.fund_avg_quarterly_return + 0.02 then 'OUTPERFORM'\n            when wfc.quarterly_return < wfc.fund_avg_quarterly_return - 0.05 then 'SIGNIFICANT_UNDERPERFORM'\n            when wfc.quarterly_return < wfc.fund_avg_quarterly_return - 0.02 then 'UNDERPERFORM'\n            else 'IN_LINE'\n        end as relative_to_fund\n    from with_fund_context wfc\n),\n\n-- ISSUE: More complex calculations and string operations\nfinal as (\n    select\n        wdm.portfolio_id,\n        wdm.portfolio_name,\n        wdm.portfolio_type,\n        wdm.fund_id,\n        wdm.quarter_end,\n        wdm.quarter_start,\n        wdm.valuation_year,\n        wdm.valuation_quarter,\n        -- ISSUE: String concatenations (slow)\n        concat('Q', wdm.valuation_quarter, ' ', wdm.valuation_year) as quarter_label,\n        concat(wdm.valuation_year, '-Q', wdm.valuation_quarter) as quarter_code,\n        concat(wdm.portfolio_name, ' (', wdm.portfolio_type, ')') as portfolio_display,\n        -- Core metrics\n        wdm.nav_usd,\n        wdm.quarterly_return,\n        wdm.benchmark_quarterly_return,\n        wdm.quarterly_excess_return,\n        wdm.portfolio_return_1y as trailing_1y_return,\n        wdm.portfolio_cumulative_return as since_inception_return,\n        wdm.sharpe_ratio,\n        wdm.sortino_ratio,\n        wdm.max_drawdown,\n        wdm.performance_rating,\n        wdm.risk_adjusted_rating,\n        -- Cashflow metrics\n        wdm.quarterly_contributions,\n        wdm.quarterly_distributions,\n        wdm.quarterly_dividends,\n        wdm.quarterly_fees,\n        wdm.quarterly_net_cashflow,\n        wdm.cumulative_contributions,\n        wdm.cumulative_distributions,\n        wdm.total_transactions,\n        -- Period comparisons\n        wdm.qoq_nav_growth_pct,\n        wdm.qoq_return_change,\n        wdm.yoy_nav_growth_pct,\n        wdm.yoy_return_change,\n        wdm.two_year_nav_growth_pct,\n        -- Performance ratios\n        wdm.tvpi,\n        wdm.dpi,\n        wdm.rvpi,\n        -- Rolling metrics\n        wdm.rolling_4q_avg_return,\n        wdm.rolling_8q_avg_return,\n        wdm.rolling_4q_volatility,\n        wdm.rolling_4q_min_return,\n        wdm.rolling_4q_max_return,\n        -- Fund context\n        wdm.fund_total_nav,\n        wdm.fund_avg_quarterly_return,\n        wdm.fund_portfolio_count,\n        wdm.portfolio_weight_in_fund,\n        -- Classifications\n        wdm.performance_trend,\n        wdm.consistency_rating,\n        wdm.relative_to_fund,\n        wdm.best_quarter_rank,\n        wdm.worst_quarter_rank,\n        -- ISSUE: Additional derived fields (repeated calculations)\n        case\n            when wdm.cumulative_contributions > 0\n            then wdm.cumulative_distributions / wdm.cumulative_contributions * 100\n            else null\n        end as distribution_yield_pct,\n        case\n            when wdm.cumulative_contributions > 0\n            then wdm.cumulative_fees / wdm.cumulative_contributions * 100\n            else null\n        end as fee_burden_pct\n    from with_derived_metrics wdm\n)\n\nselect * from final\norder by portfolio_id, quarter_end", "relation_name": "DBT_DEMO.DEV_pipeline_c.report_lp_quarterly", "batch_results": null}], "elapsed_time": 60.63701295852661, "args": {"populate_cache": true, "select": [], "warn_error_options": {"error": [], "warn": [], "silence": []}, "require_all_warnings_handled_by_warn_error": false, "quiet": false, "log_level_file": "debug", "write_json": true, "cache_selected_only": false, "require_nested_cumulative_type_params": false, "empty": false, "log_path": "/Users/nedazarei/Documents/turintech/dbtproject/logs", "indirect_selection": "eager", "which": "run", "require_generic_test_arguments_property": true, "skip_nodes_if_on_run_start_fails": false, "exclude": [], "static_parser": true, "show_all_deprecations": false, "require_yaml_configuration_for_mf_time_spines": false, "log_level": "info", "invocation_command": "dbt run --full-refresh", "source_freshness_run_project_hooks": true, "send_anonymous_usage_stats": true, "macro_debugging": false, "printer_width": 80, "vars": {}, "profiles_dir": "/Users/nedazarei/Documents/turintech/dbtproject", "version_check": true, "full_refresh": true, "print": true, "upload_to_artifacts_ingest_api": false, "log_format": "default", "defer": false, "use_colors": true, "state_modified_compare_vars": false, "use_colors_file": true, "log_file_max_bytes": 10485760, "partial_parse_file_diff": true, "strict_mode": false, "state_modified_compare_more_unrendered_values": false, "favor_state": false, "validate_macro_args": false, "partial_parse": true, "require_explicit_package_overrides_for_builtin_materializations": true, "introspect": true, "require_resource_names_without_spaces": true, "log_format_file": "debug", "show_resource_report": false, "use_fast_test_edges": false, "require_batched_execution_for_custom_microbatch_strategy": false, "project_dir": "/Users/nedazarei/Documents/turintech/dbtproject"}}